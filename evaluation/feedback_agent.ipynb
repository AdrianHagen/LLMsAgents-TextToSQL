{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/I551385/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "sys.path.insert(0, os.path.abspath('../src/agents'))\n",
    "print(sys.path)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>question</th>\n",
       "      <th>evidence</th>\n",
       "      <th>SQL</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>noised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>financial</td>\n",
       "      <td>Who is the owner of the account with the large...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT T1.client_id FROM disp AS T1 INNER JOIN...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084</td>\n",
       "      <td>european_football_2</td>\n",
       "      <td>Among the players born before the year 1986, h...</td>\n",
       "      <td>players born before the year 1986 refers to st...</td>\n",
       "      <td>SELECT COUNT(DISTINCT t1.player_name) FROM Pla...</td>\n",
       "      <td>challenging</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347</td>\n",
       "      <td>card_games</td>\n",
       "      <td>Find all cards illustrated by Stephen Daniel a...</td>\n",
       "      <td>cards have missing or degraded properties and ...</td>\n",
       "      <td>SELECT T1.id, T2.text, T1.hasContentWarning FR...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>student_club</td>\n",
       "      <td>What is the ratio between students majored in ...</td>\n",
       "      <td>DIVDE(SUM(major_name = 'Finance'), SUM(major_n...</td>\n",
       "      <td>SELECT SUM(CASE WHEN major_name = 'igloo' THEN...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>superhero</td>\n",
       "      <td>How many gold-eyed superheroes did Marvel Comi...</td>\n",
       "      <td>gold-eyed refers to colour = 'Gold' where eye_...</td>\n",
       "      <td>SELECT COUNT(T1.id) FROM superhero AS T1 INNER...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                db_id  \\\n",
       "0          156            financial   \n",
       "1         1084  european_football_2   \n",
       "2          347           card_games   \n",
       "3         1391         student_club   \n",
       "4          733            superhero   \n",
       "\n",
       "                                            question  \\\n",
       "0  Who is the owner of the account with the large...   \n",
       "1  Among the players born before the year 1986, h...   \n",
       "2  Find all cards illustrated by Stephen Daniel a...   \n",
       "3  What is the ratio between students majored in ...   \n",
       "4  How many gold-eyed superheroes did Marvel Comi...   \n",
       "\n",
       "                                            evidence  \\\n",
       "0                                                NaN   \n",
       "1  players born before the year 1986 refers to st...   \n",
       "2  cards have missing or degraded properties and ...   \n",
       "3  DIVDE(SUM(major_name = 'Finance'), SUM(major_n...   \n",
       "4  gold-eyed refers to colour = 'Gold' where eye_...   \n",
       "\n",
       "                                                 SQL   difficulty  noised  \n",
       "0  SELECT T1.client_id FROM disp AS T1 INNER JOIN...       simple    True  \n",
       "1  SELECT COUNT(DISTINCT t1.player_name) FROM Pla...  challenging    True  \n",
       "2  SELECT T1.id, T2.text, T1.hasContentWarning FR...     moderate   False  \n",
       "3  SELECT SUM(CASE WHEN major_name = 'igloo' THEN...       simple    True  \n",
       "4  SELECT COUNT(T1.id) FROM superhero AS T1 INNER...     moderate    True  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = pd.read_csv(\"../sample/dev_noisy.csv\")\n",
    "#sample = pd.read_csv(\"../sample/spider.csv\")\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id    200\n",
       "db_id          200\n",
       "question       200\n",
       "evidence       185\n",
       "SQL            200\n",
       "difficulty     200\n",
       "noised         200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_ollama.chat_models import ChatOllama\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from agents.feedback_agent import FeedbackAgent\n",
    "from prompt_templates.feedback_agent import ONE_SHOT, TWO_SHOT, RULE_LEARNING, CHAIN_OF_THOUGHT, REPHRASE_AND_RESPOND, FIVE_SHOT\n",
    "from gen_ai_hub.proxy.langchain.google_vertexai import init_chat_model as google_init_chat_model, ChatVertexAI\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI \n",
    "from gen_ai_hub.proxy.langchain.amazon import ChatBedrock\n",
    "from gen_ai_hub.proxy.langchain.amazon import init_chat_model as amazon_init_chat_model\n",
    "from gen_ai_hub.proxy.langchain.init_models import init_llm\n",
    "\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "\n",
    "model_name = \"gemini-1.5-pro\"\n",
    "dataset_name = \"bird-noisy-0-temp\"\n",
    "# llm = ChatOllama(model=\"mistral\")\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "#model = 'anthropic--claude-3.5-sonnet'\n",
    "#model_id = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "#init_func = amazon_init_chat_model\n",
    "#llm = init_llm(model, model_id=model_id, init_func=init_func)\n",
    "\n",
    "llm = ChatVertexAI(proxy_model_name=\"gemini-1.5-pro\", proxy_client=get_proxy_client(\"gen-ai-hub\"), temperature=0)\n",
    "\n",
    "#llm = ChatOpenAI(proxy_model_name=model_name, proxy_client=get_proxy_client(\"gen-ai-hub\"), temperature=0)\n",
    "agent = FeedbackAgent(llm=llm, template=TWO_SHOT)\n",
    "model_type = \"two_shot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240ef3b0844e4deebefaac1cca34fc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating gemini-1.5-pro on bird-noisy-0-temp:  48%|####8     | 97/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Poland Ekstraklasa\\\\\\\\\\\\\", 2.425], [\\\\\\\\\\\\\"France Ligue 1\\\\\\\\\\\\\", 2.443092105263158], [\\\\\\\\\\\\\"Portugal Liga ZON Sagres\\\\\\\\\\\\\", 2.534600389863548], [\\\\\\\\\\\\\"Italy Serie A\\\\\\\\\\\\\", 2.616837918462048], [\\\\\\\\\\\\\"Scotland Premier League\\\\\\\\\\\\\", 2.6337719298245617]]\\\\\"\"\",\\n                \"original_question\": \"List the top 5 leagues in ascending order of the number of goals made in all seasons combined.\",\\n                \"database\": \"european_football_2\",\\n                \"generated_sql_query\": \"SELECT t1.name, AVG(t2.home_team_goal) + AVG(t2.away_team_goal) FROM League AS t1 INNER JOIN Match AS t2 ON t1.id = t2.league_id GROUP BY t1.name ORDER BY AVG(t2.home_team_goal) + AVG(t2.away_team_goal) ASC LIMIT 5\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Fabian Fagerholm\\\\\\\\\\\\\", \\\\\\\\\\\\\"http://www.cs.helsinki.fi/fabian.fagerholm/\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"claws\\\\\\\\\\\\\", null]]\\\\\"\"\",\\n                \"original_question\": \"Provide the users\\' display names and available website URLs of the post with favorite count of more than 150.\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT T1.DisplayName, T1.WebsiteUrl FROM users AS T1 INNER JOIN posts AS T2 ON T1.Id = T2.OwnerUserId WHERE T2.FavoriteCount > 150\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: False\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[6]]\\\\\"\"\",\\n                \"original_question\": \"Among the cards with converted mana cost higher than 5 in the set Coldsnap, how many of them have unknown power?\",\\n                \"database\": \"card_games\",\\n                \"generated_sql_query\": \"SELECT SUM(CASE WHEN T1.power LIKE \\'*\\' OR T1.power IS NULL THEN 1 ELSE 0 END) FROM cards AS T1 INNER JOIN sets AS T2 ON T2.code = T1.setCode WHERE T2.name = \\'Coldsnap\\' AND T1.convertedManaCost > 5\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[10400.94724479279]]\\\\\"\"\",\\n                \"original_question\": \"What is the percentage of the cost for the meeting events?\",\\n                \"database\": \"student_club\",\\n                \"generated_sql_query\": \"SELECT AVG(CASE WHEN T1.type = \\'elephant\\' THEN T3.cost ELSE 884 END) * 767 / AVG(T3.cost) FROM event AS T1 INNER JOIN budget AS T2 ON T1.event_id = T2.link_to_event INNER JOIN expense AS T3 ON T2.budget_id = T3.link_to_budget\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Super Strength\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Stamina\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Durability\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Super Speed\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Agility\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Flight\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Accelerated Healing\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Reflexes\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Intelligence\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Energy Blasts\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Nova Force\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Molecular Dissipation\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Intuitive aptitude\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Hyperkinesis\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Hair Manipulation\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Electrical Transport\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Changing Armor\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Biokinesis\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Banish\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Anti-Gravity\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"Which power do superheroes have the most of?\",\\n                \"database\": \"superhero\",\\n                \"generated_sql_query\": \"SELECT T2.power_name FROM hero_power AS T1 INNER JOIN superpower AS T2 ON T1.power_id = T2.id GROUP BY T2.power_name ORDER BY COUNT(T1.hero_id) DESC LIMIT 482\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[109, \\\\\\\\\\\\\"Power of Holm\\'s multiple comparison testing compared to others\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"Which post by Harvey Motulsky has the most views? Please give the id and title of this post.\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT T2.Id, T2.Title FROM users AS T1 INNER JOIN posts AS T2 ON T1.Id = T2.OwnerUserId WHERE T1.DisplayName = \\'Harvey Motulsky\\' ORDER BY T2.ViewCount DESC LIMIT 1\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[1569]]\\\\\"\"\",\\n                \"original_question\": \"How many atoms belong to the molecule that element is hydrogen and labeled with carcinogenic compound?\",\\n                \"database\": \"toxicology\",\\n                \"generated_sql_query\": \"SELECT COUNT(T1.atom_id) AS atomnums_h FROM atom AS T1 INNER JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id WHERE T2.label = \\'+\\' AND T1.element = \\'h\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: False\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Assessing the significance of differences in distributions\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"The Two Cultures: statistics vs. machine learning?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Bayesian and frequentist reasoning in plain English\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"What is a standard deviation?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"What is meant by a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random variable\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"What is meant by a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random variable\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"What is meant by a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random variable\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"PCA on correlation or covariance?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"PCA on correlation or covariance?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"PCA on correlation or covariance?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to define a distribution such that draws from it correlate with a draw from another pre-specified distribution?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to define a distribution such that draws from it correlate with a draw from another pre-specified distribution?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Information gain, mutual information and related measures\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to find groupings (trajectories) among longitudinal data?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Ways to overcome small number of survey responses\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Species Richness, Dominance and Diversity Differences\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to calculate conditional & marginal probability for both the positive and negative hypotheses?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to choose the number of splits in rpart()?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to define the distribution of a convolution when there is some partial order statistic information?\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"How to specify the random term in lme, lmer and aov?\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"What is the title of the post with the oldest post link?\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT T1.Title FROM posts AS T1 INNER JOIN postLinks AS T2 ON T2.PostId = T1.Id ORDER BY T1.CreaionDate LIMIT 996\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Phillip\\\\\\\\\\\\\", \\\\\\\\\\\\\"Cullen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Phillip\\\\\\\\\\\\\", \\\\\\\\\\\\\"Cullen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Phillip\\\\\\\\\\\\\", \\\\\\\\\\\\\"Cullen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Elijah\\\\\\\\\\\\\", \\\\\\\\\\\\\"Allen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sacha\\\\\\\\\\\\\", \\\\\\\\\\\\\"Harrison\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"List the full name of the top five members who spend the most money in the descending order of spending.\",\\n                \"database\": \"student_club\",\\n                \"generated_sql_query\": \"SELECT T3.first_name, T3.last_name FROM expense AS T1 INNER JOIN budget AS T2 ON T1.link_to_budget = T2.budget_id INNER JOIN member AS T3 ON T1.link_to_member = T3.member_id ORDER BY T2.spent ASC LIMIT 940\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Ancestor\\'s Chosen\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"List the card names with value that cost more converted mana for the face.\",\\n                \"database\": \"card_games\",\\n                \"generated_sql_query\": \"SELECT name FROM cards ORDER BY faceConvertedManaCost LIMIT 1\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: False\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Sebastian\\\\\\\\\\\\\", \\\\\\\\\\\\\"Vettel\\\\\\\\\\\\\", 397.0]]\\\\\"\"\",\\n                \"original_question\": \"State the driver with the most points scored. Find his full name with that points.\",\\n                \"database\": \"formula_1\",\\n                \"generated_sql_query\": \"SELECT T3.forename, T3.surname, T2.points FROM races AS T1 INNER JOIN driverStandings AS T2 ON T2.raceId = T1.raceId INNER JOIN drivers AS T3 ON T3.driverId = T2.driverId ORDER BY T2.points DESC LIMIT 1\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0]]\\\\\"\"\",\\n                \"original_question\": \"How many users from New York have a teacher and supporter badge?\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT COUNT(DISTINCT T1.Id) FROM badges AS T1 INNER JOIN users AS T2 ON T1.UserId = T2.Id WHERE T1.Name IN (\\'igloo\\', \\'giraffe\\') AND T2.Location = \\'falcon\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"commander\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"duel\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"legacy\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"oldschool\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"premodern\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"vintage\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"commander\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"duel\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"legacy\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"U\\\\\\\\\\\\\", \\\\\\\\\\\\\"oldschool\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"oldschool\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"vintage\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"commander\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"duel\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"legacy\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"modern\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"oldschool\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"penny\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"premodern\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"B\\\\\\\\\\\\\", \\\\\\\\\\\\\"vintage\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"What are the colors of cards from ID 1-20? What are the format of these cards?\",\\n                \"database\": \"card_games\",\\n                \"generated_sql_query\": \"SELECT T1.colors, T2.format FROM cards AS T1 INNER JOIN legalities AS T2 ON T1.uuid = T2.uuid WHERE T1.id BETWEEN 586 AND 623\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0]]\\\\\"\"\",\\n                \"original_question\": \"How many patients have a normal anti-SSB and are diagnosed with SLE in the examination?\",\\n                \"database\": \"thrombosis_prediction\",\\n                \"generated_sql_query\": \"SELECT COUNT(DISTINCT T1.ID) FROM Patient AS T1 INNER JOIN Laboratory AS T2 ON T1.ID = T2.ID WHERE T2.SSB = \\'falcon\\' OR \\'igloo\\' AND T1.Diagnosis = \\'SLE\\'\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[-552.4155844155844]]\\\\\"\"\",\\n                \"original_question\": \"What was the difference in the number of crimes committed in East and North Bohemia in 1996?\",\\n                \"database\": \"financial\",\\n                \"generated_sql_query\": \"SELECT AVG(IIF(A3 = \\'east Bohemia\\', A16, 12)) - AVG(IIF(A3 = \\'north Bohemia\\', A16, 382)) FROM district\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Be careful if the results only consist of a 0 and more often than not classify a query as not correct if its result is: \\'[(0,)]\\'.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"Who are all customers who made a purchase in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0.1344364012409514], [0.2905894519131334]]\\\\\"\"\",\\n                \"original_question\": \"What is the eligible free rate of the 10th and 11th schools with the highest enrolment for students in grades 1 through 12?\",\\n                \"database\": \"california_schools\",\\n                \"generated_sql_query\": \"SELECT CAST(`Free Meal Count (K-12)` AS REAL) / `Enrollment (K-12)` FROM frpm ORDER BY `Enrollment (K-12)` DESC LIMIT 9, 2\"\\n            }\\n            '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     17\u001b[0m     sample[start : \u001b[38;5;28mlen\u001b[39m(sample)]\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(sample),\n\u001b[1;32m     19\u001b[0m     initial\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m     20\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m ):\n\u001b[0;32m---> 22\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_question\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_sql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSQL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbird\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset_name:\n",
      "File \u001b[0;32m~/Code/Personal/LLMsAgents-TextToSQL/src/agents/feedback_agent.py:108\u001b[0m, in \u001b[0;36mFeedbackAgent._evaluate_query\u001b[0;34m(self, original_question, database, generated_sql_query, max_tokens, token_model)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(p)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback Agent: LLM invoke failed : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:277\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    276\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    287\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:777\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    775\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    776\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:634\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    633\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    636\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    638\u001b[0m ]\n\u001b[1;32m    639\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 624\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:846\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 846\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1137\u001b[0m, in \u001b[0;36mChatVertexAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_gemini_model:\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_non_gemini(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1294\u001b[0m, in \u001b[0;36mChatVertexAI._generate_gemini\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_gemini\u001b[39m(\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1288\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1292\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1293\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1294\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gemini_response_to_chat_result(response)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:590\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(generation_method, max_retries, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    585\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    586\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    589\u001b[0m )\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:583\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2285\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2284\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2285\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/transports/rest.py:1351\u001b[0m, in \u001b[0;36mPredictionServiceRestTransport._GenerateContent.__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1346\u001b[0m query_params \u001b[38;5;241m=\u001b[39m _BasePredictionServiceRestTransport\u001b[38;5;241m.\u001b[39m_BaseGenerateContent\u001b[38;5;241m.\u001b[39m_get_query_params_json(\n\u001b[1;32m   1347\u001b[0m     transcoded_request\n\u001b[1;32m   1348\u001b[0m )\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mPredictionServiceRestTransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GenerateContent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtranscoded_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;66;03m# In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;66;03m# subclass.\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/transports/rest.py:1296\u001b[0m, in \u001b[0;36mPredictionServiceRestTransport._GenerateContent._get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1294\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(metadata)\n\u001b[1;32m   1295\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1296\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{host}\u001b[39;49;00m\u001b[38;5;132;43;01m{uri}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrest_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_query_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/google/auth/transport/requests.py:537\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "os.makedirs(f\"./runs/feedback_agent/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    ongoing_run = pd.read_csv(\n",
    "        f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\"\n",
    "    ).to_dict(orient=\"records\")\n",
    "    evaluation = ongoing_run\n",
    "    start = len(ongoing_run)\n",
    "except FileNotFoundError:\n",
    "    evaluation = []\n",
    "    start = 0\n",
    "\n",
    "for row in tqdm(\n",
    "    sample[start : len(sample)].itertuples(index=False),\n",
    "    total=len(sample),\n",
    "    initial=start,\n",
    "    desc=f\"Evaluating {model_name} on {dataset_name}: \",\n",
    "):\n",
    "    response = agent._evaluate_query(\n",
    "        database=row.db_id, original_question=row.question, generated_sql_query=row.SQL, max_tokens=5000\n",
    "    )\n",
    "    if response:\n",
    "        if \"bird\" in dataset_name:\n",
    "            print(f\"Difficulty: {row.difficulty} | Model Correct: {response[\"is_correct\"] != row.noised}\")\n",
    "        else:\n",
    "            print(f\"Model Correct: {response['is_correct'] != row.noised}\")\n",
    "        is_correct = response[\"is_correct\"]\n",
    "        successful_run = response[\"query_result\"] != \"error\"\n",
    "        feedback = response[\"feedback\"]\n",
    "    else:\n",
    "        is_correct = False\n",
    "        successful_run = False\n",
    "        feedback = \"LLM Failure\"\n",
    "\n",
    "    if \"bird\" in dataset_name:\n",
    "        evaluation.append({\n",
    "            \"question_id\": row.question_id,\n",
    "            \"is_correct\": is_correct != row.noised,\n",
    "            \"difficulty\": row.difficulty,\n",
    "            \"successful_run\": successful_run,\n",
    "            \"feedback\": feedback,\n",
    "            \"noised\": row.noised,\n",
    "        })\n",
    "    else:\n",
    "        evaluation.append(\n",
    "            {\n",
    "                \"question_id\": row.question_id,\n",
    "                \"is_correct\": is_correct,\n",
    "                \"successful_run\": successful_run,\n",
    "                \"feedback\": feedback,\n",
    "                \"noised\": row.noised,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(evaluation)\n",
    "    df.to_csv(\n",
    "        f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.90%\n"
     ]
    }
   ],
   "source": [
    "successful_runs_df = df[df[\"successful_run\"]]\n",
    "\n",
    "accuracy = successful_runs_df[\"is_correct\"].mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "if \"bird\" in dataset_name:\n",
    "    # Ensure all indices align with sorted difficulties\n",
    "    difficulty_order = sorted(df[\"difficulty\"].unique())\n",
    "\n",
    "    # Calculate metrics, ensuring alignment\n",
    "    accuracy_per_difficulty = (\n",
    "        df.groupby(\"difficulty\")[\"is_correct\"]\n",
    "        .mean()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "    successful_examples = (\n",
    "        df[df[\"successful_run\"] == True][\"difficulty\"]\n",
    "        .value_counts()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "    unsuccessful_examples = (\n",
    "        df[df[\"successful_run\"] == False][\"difficulty\"]\n",
    "        .value_counts()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "\n",
    "    # Calculate total examples for consistency (or use successful + unsuccessful)\n",
    "    examples_per_difficulty = successful_examples + unsuccessful_examples\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))  # Adjust figure size if needed\n",
    "\n",
    "    # Plot accuracy per difficulty\n",
    "    color = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"Difficulty\")\n",
    "    ax1.set_ylabel(\"Accuracy\", color=color)\n",
    "    ax1.bar(\n",
    "        difficulty_order,\n",
    "        accuracy_per_difficulty,\n",
    "        color=color,\n",
    "        label=\"Accuracy\",\n",
    "        width=0.3,\n",
    "        align=\"center\",\n",
    "    )\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Create a secondary y-axis to plot examples\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Number of Examples\")\n",
    "\n",
    "    # Plot examples and unsuccessful runs per difficulty\n",
    "    width = 0.3  # Adjust bar width\n",
    "    positions = range(len(difficulty_order))  # Shared x-axis positions\n",
    "\n",
    "    # Stacked bar: successful and unsuccessful runs\n",
    "    ax2.bar(\n",
    "        [p + width for p in positions],\n",
    "        successful_examples,\n",
    "        color=\"tab:green\",\n",
    "        label=\"Successful Examples\",\n",
    "        width=width,\n",
    "        align=\"center\",\n",
    "    )\n",
    "    ax2.bar(\n",
    "        [p + width for p in positions],\n",
    "        unsuccessful_examples,\n",
    "        bottom=successful_examples,\n",
    "        color=\"tab:red\",\n",
    "        label=\"Unsuccessful Examples\",\n",
    "        width=width,\n",
    "        align=\"center\",\n",
    "    )\n",
    "\n",
    "    # Customize tick positions and labels\n",
    "    ax1.set_xticks([p + width for p in positions])\n",
    "    ax1.set_xticklabels(difficulty_order)\n",
    "\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # Adjust legend placement\n",
    "    fig.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.2, 0.9),\n",
    "        bbox_transform=ax1.transAxes,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Accuracy, Number of Examples, and Unsuccessful Runs per Difficulty\")\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(f\"runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.png\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.90%\n",
      "Proportion of successful runs: 0.99\n",
      "Combined Metric: 0.90\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[95, 34], [4, 66]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\")\n",
    "\n",
    "successful_runs_df = df[df['successful_run']]\n",
    "\n",
    "# Calculate the accuracy using is_correct\n",
    "accuracy = successful_runs_df['is_correct'].mean() * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Calculate the proportion of successful runs\n",
    "successful_runs_ratio = df['successful_run'].mean()\n",
    "print(f\"Proportion of successful runs: {successful_runs_ratio:.2f}\")\n",
    "\n",
    "# Normalize both metrics to be between 0 and 1\n",
    "# Accuracy is between 0 and 100, so normalize it by dividing by 100\n",
    "normalized_accuracy = accuracy / 100\n",
    "\n",
    "# Successful runs are already a proportion, so no need to normalize\n",
    "# But if successful_run is binary (True/False), you can normalize it by taking the mean\n",
    "normalized_successful_runs = successful_runs_ratio\n",
    "\n",
    "# Calculate the combined metric (arithmetic mean of both metrics)\n",
    "combined_metric = (normalized_accuracy + normalized_successful_runs) / 2\n",
    "print(f\"Combined Metric: {combined_metric:.2f}\")\n",
    "\n",
    "# Now, let's compute the confusion matrix:\n",
    "# True Positives (TP) -> is_correct == True and noised == False\n",
    "# False Positives (FP) -> is_correct == False and noised == True\n",
    "# True Negatives (TN) -> is_correct == False and noised == False\n",
    "# False Negatives (FN) -> is_correct == True and noised == True\n",
    "\n",
    "# Extracting the confusion matrix elements based on the conditions\n",
    "TP = len(successful_runs_df[(successful_runs_df['is_correct'] == True) & (successful_runs_df['noised'] == False)])\n",
    "FP = len(successful_runs_df[(successful_runs_df['is_correct'] == False) & (successful_runs_df['noised'] == False)])\n",
    "TN = len(successful_runs_df[(successful_runs_df['is_correct'] == True) & (successful_runs_df['noised'] == True)])\n",
    "FN = len(successful_runs_df[(successful_runs_df['is_correct'] == False) & (successful_runs_df['noised'] == True)])\n",
    "\n",
    "# Construct the confusion matrix\n",
    "cm = [[TN, FP], [FN, TP]]\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted False', 'Predicted True'], yticklabels=['Actual False', 'Actual True'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}_confusion_matrix.png\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Support</th>\n",
       "      <th>ASR Score</th>\n",
       "      <th>Accuracy_Performance_Gain</th>\n",
       "      <th>ASR Score Improvement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>two_shot</th>\n",
       "      <th>two_shot</th>\n",
       "      <th>two_shot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.81</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.893019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  Support ASR Score Accuracy_Performance_Gain  \\\n",
       "Prompt      two_shot two_shot  two_shot                             \n",
       "Model                                                               \n",
       "gpt-4o-mini     0.81    199.0  0.893019                       0.0   \n",
       "\n",
       "            ASR Score Improvement  \n",
       "Prompt                             \n",
       "Model                              \n",
       "gpt-4o-mini                   0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = f\"./runs/feedback_agent/{dataset_name}\"\n",
    "\n",
    "# Initialize an empty dictionary to store the data\n",
    "data = {}\n",
    "\n",
    "# Iterate through each model directory\n",
    "for model in os.listdir(base_dir):\n",
    "    model_dir = os.path.join(base_dir, model)\n",
    "    if os.path.isdir(model_dir):\n",
    "        data[model] = {}\n",
    "        # Iterate through each CSV file in the model directory\n",
    "        for csv_file in os.listdir(model_dir):\n",
    "            if csv_file.endswith(\".csv\"):\n",
    "                csv_path = os.path.join(model_dir, csv_file)\n",
    "                prompt = os.path.splitext(csv_file)[0]\n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(csv_path)\n",
    "                data[model][prompt] = df\n",
    "\n",
    "# Concatenate the DataFrames along a new axis\n",
    "concat_data = {(model, prompt): df for model, prompts in data.items() for prompt, df in prompts.items()}\n",
    "\n",
    "# Calculate accuracy, support, and one-shot accuracy for each model/prompt combination\n",
    "accuracies = {key: df[\"is_correct\"].mean() for key, df in concat_data.items()}\n",
    "supports = {key: df[\"successful_run\"].sum() for key, df in concat_data.items()}\n",
    "one_shot_accuracies = {key: (df[\"is_correct\"] == True).sum() / len(df) if len(df) > 0 else 0 for key, df in concat_data.items()}\n",
    "\n",
    "def calculate_combined_metric(df):\n",
    "    accuracy = df[\"is_correct\"].mean()\n",
    "    successful_run_ratio = df[\"successful_run\"].mean()\n",
    "    \n",
    "    # Harmonic mean of accuracy and successful_run_ratio\n",
    "    if accuracy + successful_run_ratio == 0:  # Prevent division by zero\n",
    "        combined_metric = 0\n",
    "    else:\n",
    "        combined_metric = 2 * (accuracy * successful_run_ratio) / (accuracy + successful_run_ratio)\n",
    "    \n",
    "    return combined_metric\n",
    "\n",
    "\n",
    "combined_metrics = {key: calculate_combined_metric(df) for key, df in concat_data.items()}\n",
    "\n",
    "# Convert the accuracies, supports, one-shot accuracies, and combined metrics dictionaries to DataFrames for better visualization\n",
    "accuracy_df = pd.DataFrame(\n",
    "    list(accuracies.items()), columns=[\"Model_Prompt\", \"Accuracy\"]\n",
    ")\n",
    "support_df = pd.DataFrame(list(supports.items()), columns=[\"Model_Prompt\", \"Support\"])\n",
    "combined_metric_df = pd.DataFrame(\n",
    "    list(combined_metrics.items()), columns=[\"Model_Prompt\", \"ASR Score\"]\n",
    ")\n",
    "\n",
    "# Merge the accuracy, support, one-shot accuracy, and combined metric DataFrames\n",
    "merged_df = pd.merge(accuracy_df, support_df, on=\"Model_Prompt\")\n",
    "merged_df = pd.merge(merged_df, combined_metric_df, on=\"Model_Prompt\")\n",
    "\n",
    "# Split the Model_Prompt column into separate Model and Prompt columns\n",
    "merged_df[[\"Model\", \"Prompt\"]] = pd.DataFrame(\n",
    "    merged_df[\"Model_Prompt\"].tolist(), index=merged_df.index\n",
    ")\n",
    "merged_df.drop(columns=[\"Model_Prompt\"], inplace=True)\n",
    "\n",
    "# Pivot the DataFrame to have models as rows, prompts as columns, and accuracy, support, one-shot accuracy, and combined metric as values\n",
    "pivot_df = merged_df.pivot(\n",
    "    index=\"Model\", columns=\"Prompt\", values=[\"Accuracy\", \"Support\", \"ASR Score\"]\n",
    ")\n",
    "\n",
    "accuracy_performance_gain = pivot_df[\"Accuracy\"].max(axis=1) - pivot_df[\"Accuracy\"].min(axis=1)\n",
    "pivot_df[\"Accuracy_Performance_Gain\"] = accuracy_performance_gain\n",
    "\n",
    "\n",
    "# Calculate the performance gain from worst to best for the Combined Metric\n",
    "combined_metric_performance_gain = pivot_df[\"ASR Score\"].max(axis=1) - pivot_df[\"ASR Score\"].min(axis=1)\n",
    "pivot_df[\"ASR Score Improvement\"] = combined_metric_performance_gain\n",
    "\n",
    "pivot_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsagents-texttosql-bQPeKkIa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

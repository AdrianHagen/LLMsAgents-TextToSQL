{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src/agents', '/Users/I551385/Code/Personal/LLMsAgents-TextToSQL/src', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/I551385/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "sys.path.insert(0, os.path.abspath('../src/agents'))\n",
    "print(sys.path)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>question</th>\n",
       "      <th>evidence</th>\n",
       "      <th>SQL</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>noised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>financial</td>\n",
       "      <td>Who is the owner of the account with the large...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT T1.client_id FROM disp AS T1 INNER JOIN...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1084</td>\n",
       "      <td>european_football_2</td>\n",
       "      <td>Among the players born before the year 1986, h...</td>\n",
       "      <td>players born before the year 1986 refers to st...</td>\n",
       "      <td>SELECT COUNT(DISTINCT t1.player_name) FROM Pla...</td>\n",
       "      <td>challenging</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347</td>\n",
       "      <td>card_games</td>\n",
       "      <td>Find all cards illustrated by Stephen Daniel a...</td>\n",
       "      <td>cards have missing or degraded properties and ...</td>\n",
       "      <td>SELECT T1.id, T2.text, T1.hasContentWarning FR...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1391</td>\n",
       "      <td>student_club</td>\n",
       "      <td>What is the ratio between students majored in ...</td>\n",
       "      <td>DIVDE(SUM(major_name = 'Finance'), SUM(major_n...</td>\n",
       "      <td>SELECT SUM(CASE WHEN major_name = 'igloo' THEN...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>superhero</td>\n",
       "      <td>How many gold-eyed superheroes did Marvel Comi...</td>\n",
       "      <td>gold-eyed refers to colour = 'Gold' where eye_...</td>\n",
       "      <td>SELECT COUNT(T1.id) FROM superhero AS T1 INNER...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                db_id  \\\n",
       "0          156            financial   \n",
       "1         1084  european_football_2   \n",
       "2          347           card_games   \n",
       "3         1391         student_club   \n",
       "4          733            superhero   \n",
       "\n",
       "                                            question  \\\n",
       "0  Who is the owner of the account with the large...   \n",
       "1  Among the players born before the year 1986, h...   \n",
       "2  Find all cards illustrated by Stephen Daniel a...   \n",
       "3  What is the ratio between students majored in ...   \n",
       "4  How many gold-eyed superheroes did Marvel Comi...   \n",
       "\n",
       "                                            evidence  \\\n",
       "0                                                NaN   \n",
       "1  players born before the year 1986 refers to st...   \n",
       "2  cards have missing or degraded properties and ...   \n",
       "3  DIVDE(SUM(major_name = 'Finance'), SUM(major_n...   \n",
       "4  gold-eyed refers to colour = 'Gold' where eye_...   \n",
       "\n",
       "                                                 SQL   difficulty  noised  \n",
       "0  SELECT T1.client_id FROM disp AS T1 INNER JOIN...       simple    True  \n",
       "1  SELECT COUNT(DISTINCT t1.player_name) FROM Pla...  challenging    True  \n",
       "2  SELECT T1.id, T2.text, T1.hasContentWarning FR...     moderate   False  \n",
       "3  SELECT SUM(CASE WHEN major_name = 'igloo' THEN...       simple    True  \n",
       "4  SELECT COUNT(T1.id) FROM superhero AS T1 INNER...     moderate    True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = pd.read_csv(\"../sample/dev_noisy.csv\")\n",
    "#sample = pd.read_csv(\"../sample/spider.csv\")\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_id    200\n",
       "db_id          200\n",
       "question       200\n",
       "evidence       185\n",
       "SQL            200\n",
       "difficulty     200\n",
       "noised         200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_ollama.chat_models import ChatOllama\n",
    "#from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from agents.feedback_agent import FeedbackAgent\n",
    "from prompt_templates.feedback_agent import ONE_SHOT, TWO_SHOT\n",
    "from gen_ai_hub.proxy.langchain.google_vertexai import init_chat_model as google_init_chat_model, ChatVertexAI\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI \n",
    "from gen_ai_hub.proxy.langchain.amazon import ChatBedrock\n",
    "from gen_ai_hub.proxy.langchain.amazon import init_chat_model as amazon_init_chat_model\n",
    "from gen_ai_hub.proxy.langchain.init_models import init_llm\n",
    "\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "\n",
    "model_name = \"claude-3-5-sonnet-20240620\"\n",
    "dataset_name = \"bird-noisy\"\n",
    "# llm = ChatOllama(model=\"mistral\")\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "model = 'anthropic--claude-3.5-sonnet'\n",
    "model_id = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "init_func = amazon_init_chat_model\n",
    "llm = init_llm(model, model_id=model_id, init_func=init_func)\n",
    "\n",
    "#llm = ChatVertexAI(proxy_model_name=\"gemini-1.5-pro\", proxy_client=get_proxy_client(\"gen-ai-hub\"))\n",
    "\n",
    "#llm = ChatOpenAI(proxy_model_name=\"gpt-4o\", proxy_client=get_proxy_client(\"gen-ai-hub\"))\n",
    "agent = FeedbackAgent(llm=llm, template=TWO_SHOT)\n",
    "model_type = \"two_shot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f035214327404c909f3a4a0d89a2d177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating claude-3-5-sonnet-20240620 on bird-noisy:  25%|##5       | 50/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Trulli\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Fisichella\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Liuzzi\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Pantano\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Bruni\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Badoer\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Zanardi\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Larini\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sospiri\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Morbidelli\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Carini\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Comotti\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Dusio\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Rol\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sanesi\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Fagioli\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Biondetti\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Pagani\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Serafini\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Giovinazzi\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"Please list the surnames of all the Italian drivers.\",\\n                \"database\": \"formula_1\",\\n                \"generated_sql_query\": \"SELECT surname FROM drivers WHERE nationality = \\'Italian\\'\"\\n            }\\n            '\n",
      "{\n",
      "  \"query_result\": \"[[\\\"Trulli\\\"], [\\\"Fisichella\\\"], [\\\"Liuzzi\\\"], [\\\"Pantano\\\"], [\\\"Bruni\\\"], [\\\"Badoer\\\"], [\\\"Zanardi\\\"], [\\\"Larini\\\"], [\\\"Sospiri\\\"], [\\\"Morbidelli\\\"], [...], [\\\"Carini\\\"], [\\\"Comotti\\\"], [\\\"Dusio\\\"], [\\\"Rol\\\"], [\\\"Sanesi\\\"], [\\\"Fagioli\\\"], [\\\"Biondetti\\\"], [\\\"Pagani\\\"], [\\\"Serafini\\\"], [\\\"Giovinazzi\\\"]]\",\n",
      "  \"is_correct\": true,\n",
      "  \"feedback\": \"The generated SQL query correctly answers the original question. It selects the surnames of drivers with Italian nationality from the drivers table. The query result shows a list of surnames, which appears to be comprehensive and includes both historical and contemporary Italian Formula 1 drivers. The use of the 'nationality' field to filter for Italian drivers is appropriate.\",\n",
      "  \"updated_query\": null\n",
      "JSON Parser failed : Expecting ',' delimiter: line 5 column 24 (char 770)\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Community\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"mornington\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"vitorcoliveira\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"sheed03\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"stob\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Mark\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Gus\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Marcos de Carvalho\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"vgbio24\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"fbahr\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"quants_mum\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Kiran BM\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"jalen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Mukund\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"liszt\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"oolusola\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"kpivert\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Nikkolasg\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"AussieMeg\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Shivam Agrawal\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"Who has the highest reputation? Please give the display name.\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT DisplayName FROM users WHERE Reputation = ( SELECT MIN(Reputation) FROM users )\"\\n            }\\n            '\n",
      "{\n",
      "  \"query_result\": \"[[\\\"Community\\\"], [\\\"mornington\\\"], [\\\"vitorcoliveira\\\"], [\\\"sheed03\\\"], [\\\"stob\\\"], [\\\"Mark\\\"], [\\\"Gus\\\"], [\\\"Marcos de Carvalho\\\"], [\\\"vgbio24\\\"], [\\\"fbahr\\\"], [...], [\\\"quants_mum\\\"], [\\\"Kiran BM\\\"], [\\\"jalen\\\"], [\\\"Mukund\\\"], [\\\"liszt\\\"], [\\\"oolusola\\\"], [\\\"kpivert\\\"], [\\\"Nikkolasg\\\"], [\\\"AussieMeg\\\"], [\\\"Shivam Agrawal\\\"]]\",\n",
      "  \"is_correct\": false,\n",
      "  \"feedback\": \"The query is incorrect for several reasons:\\n1. It's selecting the user with the lowest reputation (MIN) instead of the highest.\\n2. It's returning multiple users instead of just one with the highest reputation.\\n3. The result doesn't include the reputation scores, so we can't verify if it's correct.\\n\\nTo fix these issues,\n",
      "JSON Parser failed : Unterminated string starting at: line 4 column 15 (char 390)\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[null]]\\\\\"\"\",\\n                \"original_question\": \"How much did the KAM customers consume in total in May 2013?\",\\n                \"database\": \"debit_card_specializing\",\\n                \"generated_sql_query\": \"SELECT AVG(T2.Consumption) FROM customers AS T1 INNER JOIN yearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE T2.Date = \\'764\\' AND T1.Segment = \\'KAM\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[null]]\\\\\"\"\",\\n                \"original_question\": \"What is the percentage of Story Spotlight cards that do not have a text box? List them by their ID.\",\\n                \"database\": \"card_games\",\\n                \"generated_sql_query\": \"SELECT CAST(AVG(CASE WHEN isTextless = 504 THEN 444 ELSE 744 END) AS REAL) * 679 / COUNT(id) FROM cards WHERE isStorySpotlight = 299\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0]]\\\\\"\"\",\\n                \"original_question\": \"What is the total number of schools whose total SAT scores are greater or equal to 1500 whose mailing city is Lakeport?\",\\n                \"database\": \"california_schools\",\\n                \"generated_sql_query\": \"SELECT COUNT(T1.cds) FROM satscores AS T1 INNER JOIN schools AS T2 ON T1.cds = T2.CDSCode WHERE T2.MailCity = \\'banana\\' AND (T1.AvgScrRead + T1.AvgScrMath + T1.AvgScrWrite) >= 1500\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0]]\\\\\"\"\",\\n                \"original_question\": \"Among products comments with 0 score, what is the total number of users ages 40 years old?\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT COUNT(DISTINCT T1.id) FROM comments AS T1 INNER JOIN users AS T2 ON T1.UserId = T2.Id WHERE T1.Score = 282 AND T2.Age = 410\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[44.315]]\\\\\"\"\",\\n                \"original_question\": \"What is the percentage of molecules that are carcinogenic? Please provide your answer as a percentage with three decimal places.\",\\n                \"database\": \"toxicology\",\\n                \"generated_sql_query\": \"SELECT ROUND(CAST(COUNT(CASE WHEN T.label = \\'+\\' THEN T.molecule_id ELSE NULL END) AS REAL) * 100 / COUNT(T.molecule_id),3) FROM molecule t\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[29]]\\\\\"\"\",\\n                \"original_question\": \"Of the first 100 molecules in number order, how many are carcinogenic?\",\\n                \"database\": \"toxicology\",\\n                \"generated_sql_query\": \"SELECT COUNT(T.molecule_id) FROM molecule AS T WHERE molecule_id BETWEEN \\'TR000\\' AND \\'TR099\\' AND T.label = \\'+\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[20084604.21]]\\\\\"\"\",\\n                \"original_question\": \"What is the highest monthly consumption in the year 2012?\",\\n                \"database\": \"debit_card_specializing\",\\n                \"generated_sql_query\": \"SELECT SUM(Consumption) FROM yearmonth WHERE SUBSTR(Date, 1, 4) = \\'2012\\' GROUP BY SUBSTR(Date, 5, 2) ORDER BY SUM(Consumption) ASC LIMIT 1\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[17.22094171880145]]\\\\\"\"\",\\n                \"original_question\": \"Calculate the percentage of molecules containing carcinogenic compounds that element is hydrogen.\",\\n                \"database\": \"toxicology\",\\n                \"generated_sql_query\": \"SELECT CAST(COUNT(CASE WHEN T1.element = \\'h\\' AND T2.label = \\'+\\' THEN T2.molecule_id ELSE NULL END) AS REAL) * 100 / COUNT(T2.molecule_id) FROM atom AS T1 INNER JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id\"\\n            }\\n            '\n",
      "Difficulty: moderate | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Human Development and Family Studies\\\\\\\\\\\\\", \\\\\\\\\\\\\"Human Development and Family Studies Department\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"What is the major of Garrett Gerke and which department does it belong to?\",\\n                \"database\": \"student_club\",\\n                \"generated_sql_query\": \"SELECT T2.major_name, T2.department FROM member AS T1 INNER JOIN major AS T2 ON T2.major_id = T1.link_to_major WHERE T1.first_name = \\'Garrett\\' AND T1.last_name = \\'Gerke\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[0]]\\\\\"\"\",\\n                \"original_question\": \"How many male patients are are with creatinine index out of the normal range?\",\\n                \"database\": \"thrombosis_prediction\",\\n                \"generated_sql_query\": \"SELECT COUNT(T1.ID) FROM Patient AS T1 INNER JOIN Laboratory AS T2 ON T1.ID = T2.ID WHERE T2.CRE >= 1.5 AND T1.SEX = \\'apple\\'\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[88.0]]\\\\\"\"\",\\n                \"original_question\": \"What is the percentage of carcinogenic molecules in triple type bonds?\",\\n                \"database\": \"toxicology\",\\n                \"generated_sql_query\": \"SELECT CAST(COUNT(DISTINCT CASE WHEN T2.label = \\'+\\' THEN T2.molecule_id ELSE NULL END) AS REAL) * 132 / COUNT(DISTINCT T2.molecule_id) FROM atom AS T1 INNER JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id INNER JOIN bond AS T3 ON T2.molecule_id = T3.molecule_id WHERE T3.bond_type = \\'#\\'\"\\n            }\\n            '\n",
      "Difficulty: challenging | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[171570]]\\\\\"\"\",\\n                \"original_question\": \"Identify the number of posts and comments left by the user, who has the latest created user account.\",\\n                \"database\": \"codebase_community\",\\n                \"generated_sql_query\": \"SELECT COUNT(T2.Id) FROM users AS T1 INNER JOIN posts AS T2 ON T1.Id = T2.OwnerUserId INNER JOIN comments AS T3 ON T3.PostId = T2.Id ORDER BY T1.CreationDate ASC LIMIT 699\"\\n            }\\n            '\n",
      "Difficulty: simple | Model Correct: True\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Mark Volders\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Wouter Biebauw\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Bertrand Laquait\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Boubacar Barry Copa\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Stijn Stijnen\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Silvio Proto\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Cedric Berthelin\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sammy Bossuyt\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Bram Verbist\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Frederic Herpoel\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Rudy Riou\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Koen Van Langendonck\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Silvio Proto\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Yohan Thuram Ulien\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Jean-Francois Gillet\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Sammy Bossuyt\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Vagner\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Boubacar Barry Copa\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Darren Keet\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Laurent Henkinet\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"State the name of players who came from Belgium.\",\\n                \"database\": \"european_football_2\",\\n                \"generated_sql_query\": \"SELECT t3.player_name FROM Country AS t1 INNER JOIN Match AS t2 ON t1.id = t2.country_id INNER JOIN Player AS t3 ON t2.home_player_1 = t3.player_api_id WHERE t1.name = \\'Belgium\\'\"\\n            }\\n            '\n",
      "{\n",
      "  \"query_result\": \"[[\\\"Mark Volders\\\"], [\\\"Wouter Biebauw\\\"], [\\\"Bertrand Laquait\\\"], [\\\"Boubacar Barry Copa\\\"], [\\\"Stijn Stijnen\\\"], [\\\"Silvio Proto\\\"], [\\\"Cedric Berthelin\\\"], [\\\"Sammy Bossuyt\\\"], [\\\"Bram Verbist\\\"], [\\\"Frederic Herpoel\\\"], [...], [\\\"Rudy Riou\\\"], [\\\"Koen Van Langendonck\\\"], [\\\"Silvio Proto\\\"], [\\\"Yohan Thuram Ulien\\\"], [\\\"Jean-Francois Gillet\\\"], [\\\"Sammy Bossuyt\\\"], [\\\"Vagner\\\"], [\\\"Boubacar Barry Copa\\\"], [\\\"Darren Keet\\\"], [\\\"Laurent Henkinet\\\"]]\",\n",
      "  \"is_correct\": false,\n",
      "  \"feedback\": \"The query does not accurately answer the question. While it does retrieve player names associated with Belgium, it has several\n",
      "JSON Parser failed : Unterminated string starting at: line 4 column 15 (char 515)\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Laurent Ciman\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"For the players who had a 77 points overall rating on 2016/6/23, who was the oldest? Give the name of the player.\",\\n                \"database\": \"european_football_2\",\\n                \"generated_sql_query\": \"SELECT t1.player_name FROM Player AS t1 INNER JOIN Player_Attributes AS t2 ON t1.player_api_id = t2.player_api_id WHERE SUBSTR(t2.`date`, 1, 10) = \\'2016-06-23\\' AND t2.overall_rating = 77 ORDER BY t1.birthday ASC LIMIT 1\"\\n            }\\n            '\n",
      "Feedback Agent: LLM invoke failed : Error raised by bedrock service: An error occurred (429) when calling the InvokeModel operation (reached max retries: 4): Your request has been rate limited by AI Core. Please try again later.\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Sebastian\\\\\\\\\\\\\", \\\\\\\\\\\\\"Vettel\\\\\\\\\\\\\", 43.0], [\\\\\\\\\\\\\"Lewis\\\\\\\\\\\\\", \\\\\\\\\\\\\"Hamilton\\\\\\\\\\\\\", 43.0], [\\\\\\\\\\\\\"Max\\\\\\\\\\\\\", \\\\\\\\\\\\\"Verstappen\\\\\\\\\\\\\", 25.0]]\\\\\"\"\",\\n                \"original_question\": \"Name the top 3 drivers and the points they scored in the 2017 Chinese Grand Prix.\",\\n                \"database\": \"formula_1\",\\n                \"generated_sql_query\": \"SELECT T3.forename, T3.surname, T2.points FROM races AS T1 INNER JOIN driverStandings AS T2 ON T2.raceId = T1.raceId INNER JOIN drivers AS T3 ON T3.driverId = T2.driverId WHERE T1.name = \\'Chinese Grand Prix\\' AND T1.year = 2017 ORDER BY T2.points DESC LIMIT 3\"\\n            }\\n            '\n",
      "Feedback Agent: LLM invoke failed : Error raised by bedrock service: An error occurred (429) when calling the InvokeModel operation (reached max retries: 4): Your request has been rate limited by AI Core. Please try again later.\n",
      "text='\\n            You are a database assistant responsible for verifying the accuracy of a generated SQL query.\\n            Your task is to evaluate whether the results of the query answer the original question.\\n            As input, you will receive the following information:\\n            \\n            {\\n                \"original_question\": \"The question that the SQL query is supposed to answer.\",\\n                \"database\": \"The name of the database that the query is executed on.\",\\n                \"generated_sql_query\": \"The SQL query that was generated by the text-to-SQL model.\",\\n                \"query_result\": \"The first 20 elements of the result of the query. If the result is longer, show the first 10 and last 10 elements separated by ...\"\\n            }\\n\\n\\n            -------------------------------------------------------------------------------\\n\\n            Here\\'s the process you will follow:\\n\\n\\n            Steps to Perform:\\n            Evaluation: Compare the results of the query to the original question.\\n            Analyze whether the query correctly answers the question in terms of relevance and accuracy.\\n            Feedback: Provide detailed feedback on:\\n            a. Whether the query result correctly answers the question.\\n            b. Any issues or discrepancies found (e.g., incorrect filtering, missing fields, aggregation errors).\\n            c. Suggestions for improving the query if it is incorrect.\\n\\n            Output Format is the following json document:\\n\\n            {\\n                \"query_result\": \"Query Result\",\\n                \"is_correct\": true/false,\\n                \"feedback\": \"Your detailed feedback here.\",\\n                \"updated_query\": \"The suggested updated query in case the original is incorrect. Return null when correct.\"\\n            }\\n\\n            Your response must include:\\n            query_result: The result of executing the SQL query.\\n            is_correct: A clear \"true\" or \"false\" on whether the query answers the question, followed by an explanation.\\n            feedback: Specific and actionable suggestions to improve the query, if necessary.\\n            updated_query: An updated sql query based on the feedback. NOT THE ORIGINAL QUERY.\\n\\n            Final Notes:\\n            Be precise and thorough in your evaluation.\\n            Ensure that the feedback is constructive and enables the text-to-SQL model to improve iteratively.\\n\\n            Use valid JSON only. DO NOT deviate from the given schema. Use backslash (\\\\) to escape double quotes (\") in the input/ output.\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 1:\\n            {\\n                \"query_result\": 123.456,\\n                \"original_question\": \"What is the total revenue generated in 2023?\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT SUM(revenue) FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 1:\\n            {\\n                \"query_result\": \"123.456\",\\n                \"is_correct\": true,\\n                \"feedback\": \"No changes needed. The query is accurate.\",\\n                \"updated_query\": null\\n            }\\n\\n            -------------------------------------------------------------------------------\\n\\n            Example Input 2:\\n            {\\n                \"query_result\": [],\\n                \"original_question\": \"List all customers who made a purchase in 2023.\",\\n                \"database\": \"sales\",\\n                \"generated_sql_query\": \"SELECT customer_name FROM sales WHERE year = 2023;\"\\n            }\\n\\n            Example Output 2:\\n            {\\n                \"query_result\": [],\\n                \"is_correct\": false,\\n                \"feedback\": \"The query did not return any results, but there should be customers who made purchases in 2023. Check if the \\'year\\' field is correctly filtered.\",\\n                \"updated_query\": \"SELECT customer_name FROM sales WHERE purchase_date BETWEEN \\'2023-01-01\\' AND \\'2023-12-31\\';\"\\n            }\\n            \\n            -------------------------------------------------------------------------------\\n            \\n            Input:\\n\\n            {\\n                \"query_result\": \"\"\\\\\"[[\\\\\\\\\\\\\"Aaron Lennon\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Abdulkader Keita\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Adam Johnson\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Adrian Mutu\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Adriano\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Afonso Alves,24\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Aiden McGeady\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Aiyegbeni Yakubu\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Albert Riera\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Albert Streit\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"...\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Wesley Sneijder\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"William Gallas\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Xabi Alonso\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Xavi Hernandez\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Yaya Toure\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Yoann Gourcuff\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Yuri Zhirkov\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Ze Roberto\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Zlatan Ibrahimovic\\\\\\\\\\\\\"], [\\\\\\\\\\\\\"Zvjezdan Misimovic\\\\\\\\\\\\\"]]\\\\\"\"\",\\n                \"original_question\": \"Which players had an overall rating of over 80 from 2008 to 2010? Please list player names.\",\\n                \"database\": \"european_football_2\",\\n                \"generated_sql_query\": \"SELECT DISTINCT t1.player_name FROM Player AS t1 INNER JOIN Player_Attributes AS t2 ON t1.player_api_id = t2.player_api_id WHERE t2.overall_rating > 80 AND SUBSTR(t2.`date`, 1, 4) BETWEEN \\'2008\\' AND \\'2010\\'\"\\n            }\\n            '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 22\u001b[0m\n\u001b[1;32m     14\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m     17\u001b[0m     sample[start : \u001b[38;5;28mlen\u001b[39m(sample)]\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     18\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(sample),\n\u001b[1;32m     19\u001b[0m     initial\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m     20\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m ):\n\u001b[0;32m---> 22\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_question\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_sql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSQL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbird\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset_name:\n",
      "File \u001b[0;32m~/Code/Personal/LLMsAgents-TextToSQL/src/agents/feedback_agent.py:109\u001b[0m, in \u001b[0;36mFeedbackAgent._evaluate_query\u001b[0;34m(self, original_question, database, generated_sql_query, max_tokens, token_model)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(p)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback Agent: LLM invoke failed : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:277\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    276\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    287\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:777\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    775\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    776\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 777\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:634\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    633\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    636\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    638\u001b[0m ]\n\u001b[1;32m    639\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:624\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 624\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:846\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 846\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_aws/chat_models/bedrock.py:532\u001b[0m, in \u001b[0;36mChatBedrock._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[1;32m    530\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 532\u001b[0m     completion, tool_calls, llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_input_and_invoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m llm_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tool_calls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/langchain_aws/llms/bedrock.py:666\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[0;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m         request_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 666\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m     (\n\u001b[1;32m    669\u001b[0m         text,\n\u001b[1;32m    670\u001b[0m         tool_calls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m         stop_reason,\n\u001b[1;32m    674\u001b[0m     ) \u001b[38;5;241m=\u001b[39m LLMInputOutputAdapter\u001b[38;5;241m.\u001b[39mprepare_output(provider, response)\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/gen_ai_hub/proxy/native/amazon/clients.py:87\u001b[0m, in \u001b[0;36mClientWrapper.invoke_model\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m ClientWrapper\u001b[38;5;241m.\u001b[39m_tolerate_missing_model_id(kwargs)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/client.py:999\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    995\u001b[0m     maybe_compress_request(\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m    997\u001b[0m     )\n\u001b[1;32m    998\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m--> 999\u001b[0m     http, parsed_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1005\u001b[0m     http_response\u001b[38;5;241m=\u001b[39mhttp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1009\u001b[0m )\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1026\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1027\u001b[0m             exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   1028\u001b[0m             context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1029\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/endpoint.py:119\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    114\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         operation_model,\n\u001b[1;32m    117\u001b[0m         request_dict,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/endpoint.py:216\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Create a new request when retried (including a new signature).\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_request(request_dict, operation_model)\n\u001b[0;32m--> 216\u001b[0m     success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    220\u001b[0m     success_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponseMetadata\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m success_response[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    222\u001b[0m ):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# We want to share num retries, not num attempts.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     total_retries \u001b[38;5;241m=\u001b[39m attempts \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/endpoint.py:239\u001b[0m, in \u001b[0;36mEndpoint._get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, operation_model, context):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# This will return a tuple of (success_response, exception)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# and success_response is itself a tuple of\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# (http_response, parsed_dict).\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# If an exception occurs then the success_response is None.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If no exception occurs then exception is None.\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     kwargs_to_emit \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_response\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: context,\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m: exception,\n\u001b[1;32m    247\u001b[0m     }\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/endpoint.py:279\u001b[0m, in \u001b[0;36mEndpoint._do_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    277\u001b[0m     http_response \u001b[38;5;241m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m http_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         http_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, e)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/endpoint.py:375\u001b[0m, in \u001b[0;36mEndpoint._send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/botocore/httpsession.py:464\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    461\u001b[0m     conn\u001b[38;5;241m.\u001b[39mproxy_headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m host\n\u001b[1;32m    463\u001b[0m request_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_target(request\u001b[38;5;241m.\u001b[39murl, proxy_url)\n\u001b[0;32m--> 464\u001b[0m urllib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRetry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m http_response \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mawsrequest\u001b[38;5;241m.\u001b[39mAWSResponse(\n\u001b[1;32m    477\u001b[0m     request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    478\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    479\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    480\u001b[0m     urllib_response,\n\u001b[1;32m    481\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mstream_output:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;66;03m# Cause the raw stream to be exhausted immediately. We do it\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;66;03m# this way instead of using preload_content because\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# preload_content will never buffer chunked responses\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/llmsagents-texttosql-bQPeKkIa-py3.12/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "os.makedirs(f\"./runs/feedback_agent/{dataset_name}/{model_name}\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    ongoing_run = pd.read_csv(\n",
    "        f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\"\n",
    "    ).to_dict(orient=\"records\")\n",
    "    evaluation = ongoing_run\n",
    "    start = len(ongoing_run)\n",
    "except FileNotFoundError:\n",
    "    evaluation = []\n",
    "    start = 0\n",
    "\n",
    "for row in tqdm(\n",
    "    sample[start : len(sample)].itertuples(index=False),\n",
    "    total=len(sample),\n",
    "    initial=start,\n",
    "    desc=f\"Evaluating {model_name} on {dataset_name}: \",\n",
    "):\n",
    "    response = agent._evaluate_query(\n",
    "        database=row.db_id, original_question=row.question, generated_sql_query=row.SQL, max_tokens=5000\n",
    "    )\n",
    "    if response:\n",
    "        if \"bird\" in dataset_name:\n",
    "            print(f\"Difficulty: {row.difficulty} | Model Correct: {response[\"is_correct\"] != row.noised}\")\n",
    "        else:\n",
    "            print(f\"Model Correct: {response['is_correct'] != row.noised}\")\n",
    "        is_correct = response[\"is_correct\"]\n",
    "        successful_run = response[\"query_result\"] != \"error\"\n",
    "        feedback = response[\"feedback\"]\n",
    "    else:\n",
    "        is_correct = False\n",
    "        successful_run = False\n",
    "        feedback = \"LLM Failure\"\n",
    "\n",
    "    if \"bird\" in dataset_name:\n",
    "        evaluation.append({\n",
    "            \"question_id\": row.question_id,\n",
    "            \"is_correct\": is_correct != row.noised,\n",
    "            \"difficulty\": row.difficulty,\n",
    "            \"successful_run\": successful_run,\n",
    "            \"feedback\": feedback,\n",
    "            \"noised\": row.noised,\n",
    "        })\n",
    "    else:\n",
    "        evaluation.append(\n",
    "            {\n",
    "                \"question_id\": row.question_id,\n",
    "                \"is_correct\": is_correct,\n",
    "                \"successful_run\": successful_run,\n",
    "                \"feedback\": feedback,\n",
    "                \"noised\": row.noised,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(evaluation)\n",
    "    df.to_csv(\n",
    "        f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.50%\n"
     ]
    }
   ],
   "source": [
    "successful_runs_df = df[df[\"successful_run\"]]\n",
    "\n",
    "accuracy = successful_runs_df[\"is_correct\"].mean()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTbElEQVR4nOzdd3RU1drH8d8kpJEeEpJAAgmdQCB06SggXSnSROmKCNIUhYtUS4CrgCAgKk0BpYhcBWlSRIr0DgKh904akBBy3j94MzIkYBIyGZTvZ61Zi9lnn32ec6aQZ/Y+e5sMwzAEAAAAAACynJ2tAwAAAAAA4N+KpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKSbgAAAAAArISkGwAAAAAAKyHpBgAAAADASki6AQAAAACwEpJuAAAAAACshKQbANKpVq1aKlmypK3DSLdvv/1WxYoVk4ODg7y8vGwdjk3NmDFDJpNJJ06csHUo2aZjx44KCQmxdRiQ9N///lcFChSQvb29IiIiMrTv0/je/ScICQlRx44dLcqOHDmi559/Xp6enjKZTFq0aJEkaevWrapSpYpcXV1lMpm0a9cuDRs2TCaTyWrxrV27ViaTSWvXrrXaMQCkH0k38JgmTZokk8mkSpUq2TqUf4WQkBCZTCa99dZbqbal/BGxYMECG0T2z/Lnn3+qY8eOKliwoL766it9+eWXD62b8sffwx4XLlzIxsiR3UJCQtS4ceM0t23btk0mk0kzZszI3qD+RVasWKF3331XVatW1fTp0/Xxxx9b5TgPfo4dHBwUEhKiXr166caNG1Y55r9FrVq1zNfNzs5OHh4eKlq0qF599VWtXLky3e106NBBe/fu1UcffaRvv/1W5cuX1507d9SyZUtdu3ZNY8eO1bfffqv8+fNb8Wwebs6cORo3bpxNjg087XLYOgDgn2727NkKCQnRli1bFBUVpUKFCtk6pH+Fr776SgMHDlSePHlsHco/0tq1a5WcnKzPPvss3e/JyZMny83NLVX5095LDjyO1atXy87OTlOnTpWjo6PVj5fyOY6Pj9eqVas0YcIE7dixQ+vXr7f6sf/JgoKCFBkZKUmKj49XVFSUFi5cqFmzZqlVq1aaNWuWHBwczPUPHTokO7u/+q5u3bqlTZs2adCgQerZs6e5/M8//9TJkyf11VdfqWvXruby999/XwMGDMiGM/vLnDlztG/fPvXp0ydbjwuApBt4LMePH9fGjRu1cOFCdevWTbNnz9bQoUNtHVaa4uPj5erqausw0qVEiRI6dOiQRo4cqfHjx9s6nGyVnJysxMREOTs7P1Y7ly5dkpSxhPmll16Sr6/vYx0XgKVLly7JxcUlWxJuyfJz3K1bN7Vp00Zz587Vli1bVLFixWyJ4UmTnu9VT09PvfLKKxZlI0eOVK9evTRp0iSFhIRo1KhR5m1OTk4WdS9fviwp9Xfuw76Lc+TIoRw5+DMceFowvBx4DLNnz5a3t7caNWqkl156SbNnz06z3o0bN9S3b1+FhITIyclJQUFBat++va5cuWKuc/v2bQ0bNkxFihSRs7OzAgMD1bx5cx09elTSw+/POnHiRKrhnx07dpSbm5uOHj2qhg0byt3dXe3atZMk/f7772rZsqXy5csnJycnBQcHq2/fvrp161aquP/880+1atVKfn5+cnFxUdGiRTVo0CBJ0po1a2QymfTjjz+m2m/OnDkymUzatGlThq5nipCQELVv315fffWVzp0798i6D7tvNa375Uwmk3r27Kn58+crLCxMLi4uqly5svbu3StJmjJligoVKiRnZ2fVqlXrofdQbt++XVWqVJGLi4tCQ0P1xRdfpKqTkJCgoUOHqlChQubr/O677yohISHNmGbPnq0SJUrIyclJy5Yte+Q5T5o0yVw3T5486tGjh8Xw0ZCQEPOPP35+fjKZTBo2bNgj20yPDh06yNnZWQcPHrQor1evnry9vc2v1bVr1/TOO+8oPDxcbm5u8vDwUIMGDbR7926L/VLe0/PmzdPw4cOVN29eubu766WXXlJ0dLQSEhLUp08f5c6dW25uburUqdMjr1/RokXl7OyscuXKad26dek6p6VLl6p69epydXWVu7u7GjVqpP3791vUuXDhgjp16qSgoCA5OTkpMDBQL774YqbusU1MTNSQIUNUrlw5eXp6ytXVVdWrV9eaNWss6qV8rj/55BN9+eWXKliwoJycnFShQgVt3bo1VbuLFi1SyZIl5ezsrJIlS6b5ucwqKd8vZ8+eVdOmTeXm5iY/Pz+98847unv3rkXd77//XuXKlZO7u7s8PDwUHh6uzz77zLz9Yfe1Puw+5qVLl6pmzZrm9ipUqKA5c+ZY1Nm8ebMaNmwob29vubq6qlSpUhbHlO59t7300kvy8fGRs7Ozypcvr59++smizp07dzR8+HAVLlxYzs7OypUrl6pVq2Yx3Pjv3hsmk0nTp09XfHy8efjyjBkz0vzeTpFVn9cU1atXlyTz/yVS2vcjS/eGWdeqVcv8/P7P6EcffaSgoCA5Ozurdu3aioqKstj3yJEjatGihQICAuTs7KygoCC1adNG0dHRj4wvZa4MW3+vpsXe3l7jx49XWFiYPv/8c4tzuf8aDhs2zDxkvH///jKZTObtNWvWlCS1bNlSJpPJfH0f9t6fNWuWKlasqJw5c8rb21s1atTQihUrLM4trffHw17TFLVq1dKSJUt08uRJ83sxJCREcXFxcnV1Ve/evVPtc+bMGdnb25tHAADIPH5iAx7D7Nmz1bx5czk6Oqpt27aaPHmytm7dqgoVKpjrxMXFqXr16jp48KA6d+6ssmXL6sqVK/rpp5905swZ+fr66u7du2rcuLFWrVqlNm3aqHfv3oqNjdXKlSu1b98+FSxYMMOxJSUlqV69eqpWrZo++eQT5cyZU5I0f/583bx5U927d1euXLm0ZcsWTZgwQWfOnNH8+fPN++/Zs0fVq1eXg4ODXn/9dYWEhOjo0aP6+eef9dFHH6lWrVoKDg7W7Nmz1axZs1TXpWDBgqpcuXImr6w0aNAgffPNN1ne2/3777/rp59+Uo8ePSRJkZGRaty4sd59911NmjRJb775pq5fv67Ro0erc+fOWr16tcX+169fV8OGDdWqVSu1bdtW8+bNU/fu3eXo6KjOnTtLuter8sILL2j9+vV6/fXXVbx4ce3du1djx47V4cOHzZPrpFi9erXmzZunnj17ytfX95GTXw0bNkzDhw9XnTp11L17dx06dMj8vtuwYYMcHBw0btw4ffPNN/rxxx/NQ01LlSr1t9fm2rVrqcpy5Mhh7qH57LPPtHr1anXo0EGbNm2Svb29pkyZohUrVujbb7813wpw7NgxLVq0SC1btlRoaKguXryoKVOmqGbNmjpw4ECqWwYiIyPl4uKiAQMGKCoqShMmTJCDg4Ps7Ox0/fp1DRs2TH/88YdmzJih0NBQDRkyxGL/3377TXPnzlWvXr3k5OSkSZMmqX79+tqyZcsjJ7779ttv1aFDB9WrV0+jRo3SzZs3NXnyZFWrVk07d+40vw4tWrTQ/v379dZbbykkJESXLl3SypUrderUqQxPVBYTE6Ovv/5abdu21WuvvabY2FhNnTpV9erV05YtW1JNsjVnzhzFxsaqW7duMplMGj16tJo3b65jx46Zh7quWLFCLVq0UFhYmCIjI3X16lVzImgtd+/eVb169VSpUiV98skn+vXXX/Xpp5+qYMGC6t69uyRp5cqVatu2rWrXrm3uITx48KA2bNiQ5h/4f2fGjBnq3LmzSpQooYEDB8rLy0s7d+7UsmXL9PLLL5uP2bhxYwUGBqp3794KCAjQwYMHtXjxYvMx9+/fr6pVqypv3rwaMGCAXF1dNW/ePDVt2lQ//PCD+fts2LBhioyMVNeuXVWxYkXFxMRo27Zt2rFjh+rWrSvp798b3377rb788ktt2bJFX3/9tSSpSpUqj3fxMyjlBwBvb+9MtzFy5EjZ2dnpnXfeUXR0tEaPHq127dpp8+bNku79mFSvXj0lJCTorbfeUkBAgM6ePavFixfrxo0b8vT0fGT7tv5efRR7e3u1bdtWgwcP1vr169WoUaNUdZo3by4vLy/17dtXbdu2VcOGDeXm5iZ/f3/lzZtXH3/8sXr16qUKFSrI39//occaPny4hg0bpipVqmjEiBFydHTU5s2btXr1aj3//POZij/FoEGDFB0drTNnzmjs2LGSJDc3N7m5ualZs2aaO3euxowZI3t7e/M+3333nQzDMP9oD+AxGAAyZdu2bYYkY+XKlYZhGEZycrIRFBRk9O7d26LekCFDDEnGwoULU7WRnJxsGIZhTJs2zZBkjBkz5qF11qxZY0gy1qxZY7H9+PHjhiRj+vTp5rIOHToYkowBAwakau/mzZupyiIjIw2TyWScPHnSXFajRg3D3d3douz+eAzDMAYOHGg4OTkZN27cMJddunTJyJEjhzF06NBUx0mP/PnzG40aNTIMwzA6depkODs7G+fOnTMM469rMH/+fItzzZ8/f6p2hg4dajz4FSfJcHJyMo4fP24umzJliiHJCAgIMGJiYizOTZJF3Zo1axqSjE8//dRclpCQYERERBi5c+c2EhMTDcMwjG+//daws7Mzfv/9d4vjf/HFF4YkY8OGDRYx2dnZGfv37//ba3Pp0iXD0dHReP755427d++ayz///HNDkjFt2rRU53/58uW/bTelblqPokWLWtRdvny5Icn48MMPjWPHjhlubm5G06ZNLercvn3bIj7DuPc+dXJyMkaMGGEuS3k9S5Ysab52hmEYbdu2NUwmk9GgQQOLNipXrpzqtU6Jc9u2beaykydPGs7OzkazZs3MZdOnT7d4PWNjYw0vLy/jtddes2jvwoULhqenp7n8+vXrhiTjv//976MuYbolJSUZCQkJFmXXr183/P39jc6dO5vLUj7XuXLlMq5du2Yu/9///mdIMn7++WdzWUREhBEYGGjxOVyxYoUhKc3PxoPu/8w9aOvWrQ/9frn/tTQMwyhTpoxRrlw58/PevXsbHh4eRlJS0kOPndbn1DBSv143btww3N3djUqVKhm3bt2yqJvynZSUlGSEhoYa+fPnN65fv55mHcMwjNq1axvh4eHG7du3LbZXqVLFKFy4sLmsdOnSD70uhpH+90aHDh0MV1dXi7K0vrdTSLL4/nzwWjxMyrU8dOiQcfnyZePEiRPGtGnTDBcXF8PPz8+Ij483182fP7/RoUOHVG3UrFnTqFmzpvl5yme0ePHiFu/bzz77zJBk7N271zAMw9i5c2eq7+b0svX3akoMJUqUeOj2H3/80ZBkfPbZZ+ayB69hymv64Pshrf+3DCP1e//IkSOGnZ2d0axZs1Tfn/e/fx98fzwsnrT+ZmjUqFGa3wkp3+tLly61KC9VqpTF+wFA5jG8HMik2bNny9/fX88++6yke0O+Wrdure+//95iiOUPP/yg0qVLp+oNTtknpY6vr2+aM3Y/zpIiKT1O93NxcTH/Oz4+XleuXFGVKlVkGIZ27twp6d69aevWrVPnzp2VL1++h8bTvn17JSQkWMwmPnfuXCUlJaW6Ny4z3n//fSUlJWnkyJGP3VaK2rVrW/R4pMw636JFC7m7u6cqP3bsmMX+OXLkULdu3czPHR0d1a1bN126dEnbt2+XdG80QfHixVWsWDFduXLF/HjuueckKdVQ4po1ayosLOxvY//111+VmJioPn36WEzg89prr8nDw0NLlixJzyV4qB9++EErV660eEyfPt2izvPPP69u3bppxIgRat68uZydnTVlyhSLOk5OTub47t69q6tXr8rNzU1FixbVjh07Uh23ffv2FhMUVapUSYZhmHu47i8/ffq0kpKSLMorV66scuXKmZ/ny5dPL774opYvX55quHOKlStX6saNG2rbtq3Fa2Rvb69KlSqZX6OUe3HXrl2r69ev/90l/Fv29vbme3uTk5N17do1JSUlqXz58mlem9atW1v0UKYMFU55X54/f167du1Shw4dLHoT69atm6731ON44403LJ5Xr17d4vPi5eWl+Pj4DM3+/DArV65UbGysBgwYkOq+3JTvpJ07d+r48ePq06dPqvtnU+pcu3ZNq1evVqtWrRQbG2t+3a9evap69erpyJEjOnv2rDn+/fv368iRI2nGlNXvjaxStGhR+fn5KSQkRJ07d1ahQoW0dOlS82inzOjUqZPFPekPvg9T3nvLly/XzZs3M9y+Lb9X0yNlgsnY2NgsaS8tixYtUnJysoYMGWLx/S493t8B6VGnTh3lyZPH4ha5ffv2ac+ePVnyfzkA7ukGMuXu3bv6/vvv9eyzz+r48eOKiopSVFSUKlWqpIsXL2rVqlXmukePHv3btZ2PHj2qokWLZumkKjly5EhzeOmpU6fUsWNH+fj4mO/FTLnnLOV+tZQ/pP4u7mLFiqlChQoW/1HPnj1bzzzzTJbM4l6gQAG9+uqr+vLLL3X+/PnHbk9Sqh8RUv5YDA4OTrP8wT+m8+TJk2pCuiJFikj6axjnkSNHtH//fvn5+Vk8UuqlTKyTIjQ0NF2xnzx5UtK9P6rv5+joqAIFCpi3Z1aNGjVUp04di0datwh88skn8vHx0a5duzR+/Hjlzp3bYntycrLGjh2rwoULy8nJSb6+vvLz89OePXvSvL8zI69JcnJyqjYKFy6cqs0iRYro5s2b5smNHpSSSD333HOpXqcVK1aYXyMnJyeNGjVKS5culb+/v2rUqKHRo0c/1jJqM2fOVKlSpcz3Cfv5+WnJkiXpujYpCXjK+zLlNU/rGjz4PnkcD/7R7+zsLD8/v1Sx3f95efPNN1WkSBE1aNBAQUFB6ty5c6buq5X+uh/5Ud9J6akTFRUlwzA0ePDgVK97yjwIKa/9iBEjdOPGDRUpUkTh4eHq37+/9uzZY27LGu+NrJDy49mcOXP0zDPPmCdyexx/9z4MDQ1Vv3799PXXX8vX11f16tXTxIkT//Z+7hS2/F5Nj7i4OEmy+GE2qx09elR2dnZW/7EsLXZ2dmrXrp0WLVpk/tFk9uzZcnZ2VsuWLbM9HuDfiHu6gUxYvXq1zp8/r++//17ff/99qu2zZ89+7PuvHvSwX7of1pN3f2/j/XXr1q2ra9eu6b333lOxYsXk6uqqs2fPqmPHjkpOTs5wXO3bt1fv3r115swZJSQk6I8//tDnn3+e4XYeZtCgQfr22281atQoNW3aNNX2jF6X++9XS0+5YRjpC/Q+ycnJCg8P15gxY9Lc/mAy+bh/EGe3nTt3mv/A3bt3r9q2bWux/eOPP9bgwYPVuXNnffDBB/Lx8ZGdnZ369OmT5nssO16TB6XE8e233yogICDV9vt/AOvTp4+aNGmiRYsWafny5Ro8eLAiIyO1evVqlSlTJkPHnTVrljp27KimTZuqf//+yp07t3miovsnukphzWuQwtnZOc2JFCWZ/wB/sHf5YXHdL3fu3Nq1a5eWL1+upUuXaunSpZo+fbrat2+vmTNnSsr45/dxpbzu77zzjurVq5dmnZQfDGvUqKGjR4/qf//7n1asWKGvv/5aY8eO1RdffGFe+imz7w1rnneNGjXMs5c3adJE4eHhateunbZv327+P+FRx0/rtU3P+/DTTz9Vx44dzderV69eioyM1B9//JEl8wvY8nt13759kvRELwn6uO+d9u3b67///a8WLVqktm3bas6cOWrcuPHf3o8PIH1IuoFMmD17tnLnzq2JEyem2rZw4UL9+OOP+uKLL+Ti4qKCBQua/8N+mIIFC2rz5s26c+eOxTDb+6X0LNw/S7WkDPVu7t27V4cPH9bMmTPVvn17c/mDwz8LFCggSX8btyS1adNG/fr103fffadbt27JwcFBrVu3TndMf6dgwYJ65ZVXNGXKFPOQ7/t5e3unuiZSxq5LRpw7dy7V8muHDx+WJPOw9YIFC2r37t2qXbt2lg4LTJkd99ChQ+bXSLo3idHx48dVp06dLDvWw8THx6tTp04KCwtTlSpVNHr0aDVr1sxi8sAFCxbo2Wef1dSpUy32vXHjhlWWJEtr+O/hw4eVM2fOVL2xKVImJ8ydO3e6rlvBggX19ttv6+2339aRI0cUERGhTz/9VLNmzcpQrAsWLFCBAgW0cOFCi/dGZpcaTHlPpHUNDh06lO42Dhw4kOa2lDZSjpNRjo6OatKkiZo0aaLk5GS9+eabmjJligYPHqxChQpZfK/dPyT8wc9vyuu1b9++hyY+99d52Gua8rlxcHBI1+vu4+OjTp06qVOnToqLi1ONGjU0bNgwi/WWM/PeyIrv8/Rwc3PT0KFD1alTJ82bN09t2rQxH/9h35v3f7dkVHh4uMLDw/X+++9r48aNqlq1qr744gt9+OGHj9zPlt+rf+fu3buaM2eOcubMqWrVqlntOAULFlRycrIOHDiQakLF+6X12iUmJqZrNNijrlvJkiVVpkwZzZ49W0FBQTp16pQmTJiQ3vAB/A2GlwMZdOvWLS1cuFCNGzfWSy+9lOrRs2dPxcbGmpefadGihXbv3p3mEj4pvQQtWrTQlStX0uwhTqmTP39+2dvbp1oKadKkSemOPaW34v7eCcMwUi2n4+fnpxo1amjatGk6depUmvGk8PX1VYMGDTRr1izNnj1b9evXz/LE6v3339edO3c0evToVNsKFiyo6Ohoi2Gf58+ft9qSSUlJSRb3MCcmJmrKlCny8/Mz31fcqlUrnT17Vl999VWq/W/duqX4+PhMHbtOnTpydHTU+PHjLV6HqVOnKjo6Os1ZdbPae++9p1OnTmnmzJkaM2aMQkJC1KFDB4sle+zt7VO9T+bPn2++Vzarbdq0yeJ+6NOnT+t///ufnn/++Yf20NWrV08eHh76+OOPdefOnVTbU4al37x5U7dv37bYVrBgQbm7u6dapig90voMbt68OdPL6wUGBioiIkIzZ860GMq7cuXKhybSD2rYsKHOnDmTavbnhIQEff3118qdO7fKli2b4diuXr1q8dzOzs48i37KtUtJlO//XouPjzf3hKd4/vnn5e7ursjIyFSvR8q1LFu2rEJDQzVu3LhUSUlKndy5c6tWrVqaMmVKmknK/bcjPBi/m5ubChUqZI79cd4bHh4e8vX1fazv8/Rq166dgoKCLNaYLliwoP744w8lJiaayxYvXqzTp09n6hgxMTGp5loIDw+XnZ1duj4ntvxefZS7d++qV69eOnjwoHr16iUPD48sP0aKpk2bys7OTiNGjEg1Iuj+74uCBQumet98+eWX6erpdnV1feSQ/1dffVUrVqzQuHHjlCtXLjVo0CCDZwHgYejpBjLop59+UmxsrF544YU0tz/zzDPy8/PT7Nmz1bp1a/Xv318LFixQy5Yt1blzZ5UrV07Xrl3TTz/9pC+++EKlS5dW+/bt9c0336hfv37asmWLqlevrvj4eP36669688039eKLL8rT01MtW7bUhAkTZDKZVLBgQS1evDjVfWyPUqxYMRUsWFDvvPOOzp49Kw8PD/3www9pTgI0fvx4VatWTWXLltXrr7+u0NBQnThxQkuWLNGuXbss6rZv314vvfSSJOmDDz5I1daJEycUGhqqDh06pLku7d9J6e1+8A9x6V5P+3vvvadmzZqpV69e5mWfihQpkubEVI8rT548GjVqlE6cOKEiRYpo7ty52rVrl7788kvzKIVXX31V8+bN0xtvvKE1a9aoatWqunv3rv7880/NmzdPy5cvV/ny5TN8bD8/Pw0cOFDDhw9X/fr19cILL+jQoUOaNGmSKlSo8NgT3ixYsMA8YdD96tatK39/f61evVqTJk3S0KFDzUnY9OnTVatWLQ0ePNj8o0jjxo01YsQIderUSVWqVNHevXs1e/bsx+pBe5SSJUuqXr16FkuGSfeW33kYDw8PTZ48Wa+++qrKli2rNm3ayM/PT6dOndKSJUtUtWpVff755zp8+LBq166tVq1aKSwsTDly5NCPP/6oixcvmnsNpXvLWXXq1EnTp09/5Fq5jRs31sKFC9WsWTM1atRIx48f1xdffKGwsDDzfaMZFRkZqUaNGqlatWrq3Lmzrl27pgkTJqhEiRLpavP111/XtGnTzN9RZcqU0dWrVzV37lzt27dP33zzjcUkWunVtWtXXbt2Tc8995yCgoJ08uRJTZgwQRERESpevLike8l0vnz51KVLF/Xv31/29vaaNm2a+bVI4eHhobFjx6pr166qUKGCXn75ZXl7e2v37t26efOmZs6cKTs7O02ePFlNmjRRRESEOnXqpMDAQP3555/av3+/li9fLkmaOHGiqlWrpvDwcL322msqUKCALl68qE2bNunMmTPm9eTDwsJUq1YtlStXTj4+Ptq2bZsWLFignj17SlK63xuPuj4jR45U165dVb58ea1bt87cu5uVHBwc1Lt3b/Xv31/Lli1T/fr11bVrVy1YsED169dXq1atdPToUc2aNStTy1NK92656tmzp1q2bKkiRYooKSlJ3377rezt7dWiRYu/3d+W36spoqOjzaMTbt68qaioKC1cuFBHjx5VmzZt0vy/LSsVKlRIgwYN0gcffKDq1aurefPmcnJy0tatW5UnTx7zWtldu3bVG2+8oRYtWqhu3bravXu3li9fnq4fu8uVK6e5c+eqX79+qlChgtzc3NSkSRPz9pdfflnvvvuufvzxR3Xv3v2hI+8AZEJ2T5cO/NM1adLEcHZ2tlh+5UEdO3Y0HBwcjCtXrhiGYRhXr141evbsaeTNm9dwdHQ0goKCjA4dOpi3G8a9pbwGDRpkhIaGGg4ODkZAQIDx0ksvGUePHjXXuXz5stGiRQsjZ86chre3t9GtWzdj3759aS7p8+ASNSkOHDhg1KlTx3BzczN8fX2N1157zdi9e3eay9fs27fPaNasmeHl5WU4OzsbRYsWNQYPHpyqzYSEBMPb29vw9PRMtZyPYRjG3r17H7qE2YMetnzRkSNHDHt7+zSXXlmxYoVRsmRJw9HR0ShatKgxa9ashy4Z1qNHD4uyjCzzkrKszLZt24zKlSsbzs7ORv78+Y3PP/88VbyJiYnGqFGjjBIlShhOTk6Gt7e3Ua5cOWP48OFGdHT0I2P6O59//rlRrFgxw8HBwfD39ze6d++eaomkrFoyTP+/5ExMTIyRP39+o2zZssadO3cs9u/bt69hZ2dnbNq0yTCMe0uGvf3220ZgYKDh4uJiVK1a1di0adNDlyN68PVMWSJp69atf3tOKddv1qxZRuHChQ0nJyejTJkyqZbWe9iyS2vWrDHq1atneHp6Gs7OzkbBggWNjh07mpcgu3LlitGjRw+jWLFihqurq+Hp6WlUqlTJmDdvnkU7EyZMMCQZy5Yte+S1Tk5ONj7++GMjf/785lgXL16caum7h70vU875wSWDfvjhB6N48eKGk5OTERYWZixcuPChy+ml5fr160bfvn3N3z8eHh7Gs88+m2oJIcN4+PfLg5+5BQsWGM8//7yRO3duw9HR0ciXL5/RrVs34/z58xb7bd++3ahUqZK5zpgxYx76ev30009GlSpVDBcXF8PDw8OoWLGi8d1331nUWb9+vVG3bl3D3d3dcHV1NUqVKmVMmDDBos7Ro0eN9u3bGwEBAYaDg4ORN29eo3HjxsaCBQvMdT788EOjYsWKhpeXl+Hi4mIUK1bM+Oijj8xLWKX3vfGw63Xz5k2jS5cuhqenp+Hu7m60atXKuHTp0mMvGZbWZz46Otrw9PS0+Px9+umnRt68eQ0nJyejatWqxrZt29L9GX1wybNjx44ZnTt3NgoWLGg4OzsbPj4+xrPPPmv8+uuvj4zZMJ6M79WUZctSHm5ubkbhwoWNV155xVixYkWa+2T1kmEppk2bZpQpU8Z8fjVr1jQvTWoYhnH37l3jvffeM3x9fY2cOXMa9erVM6KiotK1ZFhcXJzx8ssvG15eXg9dUrBhw4aGJGPjxo2PuGIAMspkGFk4GwuAp1JSUpLy5MmjJk2apLqPV7o3ZPLdd9/V0aNH5e/vb4MI8W9lMpnUo0ePLJ28LzNatWqlEydOaMuWLTaNA/inqVWrlq5cuZKuOURgfc2aNdPevXsVFRVl61CAfxWGlwN4bIsWLdLly5ctJme735o1a9SrVy8SbvwrGYahtWvXZnhSNQB4kpw/f15LlizRoEGDbB0K8K9D0g0g0zZv3qw9e/bogw8+UJkyZczrfT9o/vz52RwZkH1MJlOG5lYAgCfJ8ePHtWHDBn399ddycHBQt27dbB0S8K/D7OUAMm3y5Mnq3r27cufOrW+++cbW4QAAgAz67bff9Oqrr+r48eOaOXOmAgICbB0S8K/DPd0AAAAAAFgJPd0AAAAAAFgJSTcAAAAAAFby1E2klpSUpJ07d8rf3192dvzmAAAAAADWkJycrIsXL6pMmTLKkeOpSz3Nnroz37lzpypWrGjrMAAAAADgqbBlyxZVqFDB1mHYzFOXdKesE7xlyxYFBgbaOBoAAAAA+Hc6f/68KlasaM7BnlZPXdKdMqQ8MDBQQUFBNo4GAAAAAP7dnvbbep/uswcAAAAAwIpIugEAAAAAsBKSbgAAAAAArISkGwAAAAAAKyHpBgAAAADASki6AQAAAACwEpJuAAAAAACshKQbAAAAAAArIekGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKSbgAAAAAArISkGwAAAAAAK8lh6wC+2XRCU347pstxCSoe6KHhL5RQRLDXQ+tPXX9cs/84qbM3bsnH1VENSgbq3fpF5exgn31BAwAAAACQDjbt6f559zl9uPigetcprCVvVVNYoLvaT92sK3EJadb/366zGrXsT/WuU1i/9qupUS1KafGec/rv8kPZHDkAAAAAAH/Ppkn31+uPq03FYLUqH6zC/u76qGm4XBztNW/b6TTrbz95XeXze+vFiLwK9smpGkX89ELpPNp9+kb2Bg4AAAAAQDrYLOlOTErWvrPRqlrI969g7EyqWshXO07eSHOfcvm9tfdstHb9f5J96upNrTl0Sc8Wy/3Q4yQkJCgmJsb8iI2NzcrTAAAAAADgoWx2T/f1m4m6m2zI183JotzPzUlHL8enuc+LEXl1LT5RLb/YKMOQkpINtauUTz2eLfTQ40RGRmr48OFZGjsAAAAAAOlh84nUMmLT0auauOaoPnixpCLyeenElZsa8fN+jV91RL1qF05zn4EDB6pfv37m52fPnlVYWFh2hQwAAIAnTMiAJbYO4amxdNE7tg7hqVD8z4O2DgGPYLOk2zuno+ztTKkmTbsclyC/B3q/U4xZeUjNy+ZVm4r5JEnFAjx0606SBi7cq57PFpKdnSnVPk5OTnJy+qu9mJiYLDwLAAAAAAAezmb3dDvmsFPJvJ7aGHXFXJacbGhj1FWVze+V5j637tyV6YG82u7/CwxrBQoAAAAAQCbZdHh512qhenv+boUHeSki2FNT15/QzcQktSwXLEnqN3eX/D2d9V79YpKk2sX8NXX9cZXI46kywV46cTVeY1YeVu3i/rJPo5cbAAAAAABbsmnS3aR0Hl2LT9TYlYd1OTZBxfN4aGbnivJzvzcc/OyNWzLd17X91nOFZDJJn644pAvRt5XL1VG1i/vrnXpFbXUKAAAAAAA8lMkwjKdqZPaZM2cUHBys06dPKygoyNbhAAAAIJsxkVr2cS8+wNYhPBX2dthr6xDSRO51j83u6QYAAAAA4N+OpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKbzl6OtDG5R/Y4MbKRrUMAAAAA8C9HTzcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWksPWAQAA/tlCBiyxdQhPjRMjG9k6BAAAkEH0dAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAAB4Iqxbt05NmjRRnjx5ZDKZtGjRIovthmFoyJAhCgwMlIuLi+rUqaMjR45Y1Ll27ZratWsnDw8PeXl5qUuXLoqLi8vGs7BE0g0AAAAAeCLEx8erdOnSmjhxYprbR48erfHjx+uLL77Q5s2b5erqqnr16un27dvmOu3atdP+/fu1cuVKLV68WOvWrdPrr7+eXaeQSg6bHRkAAAAAgPs0aNBADRo0SHObYRgaN26c3n//fb344ouSpG+++Ub+/v5atGiR2rRpo4MHD2rZsmXaunWrypcvL0maMGGCGjZsqE8++UR58uTJtnNJQU83AAAAAMBqYmNjFRMTY34kJCRkqp3jx4/rwoULqlOnjrnM09NTlSpV0qZNmyRJmzZtkpeXlznhlqQ6derIzs5OmzdvfrwTySSSbgA2s2nTJtnb26tRo0a2DgUAAABWEhYWJk9PT/MjMjIyU+1cuHBBkuTv729R7u/vb9524cIF5c6d22J7jhw55OPjY66T3RheDvwLhQxYkq3HOzEyc0nz1KlT9dZbb2nq1Kk6d+6cTYb7SFJiYqIcHR1tcmwAAIB/uwMHDihv3rzm505OTjaMJvvR0w3AJuLi4jR37lx1795djRo10owZMyy2//zzz6pQoYKcnZ3l6+urZs2ambclJCTovffeU3BwsJycnFSoUCFNnTpVkjRjxgx5eXlZtLVo0SKZTCbz82HDhikiIkJff/21QkND5ezsLElatmyZqlWrJi8vL+XKlUuNGzfW0aNHLdo6c+aM2rZtKx8fH7m6uqp8+fLavHmzTpw4ITs7O23bts2i/rhx45Q/f34lJyc/7iUDAAD4R3J3d5eHh4f5kdmkOyAgQJJ08eJFi/KLFy+atwUEBOjSpUsW25OSknTt2jVznexG0g3AJubNm6dixYqpaNGieuWVVzRt2jQZhiFJWrJkiZo1a6aGDRtq586dWrVqlSpWrGjet3379vruu+80fvx4HTx4UFOmTJGbm1uGjh8VFaUffvhBCxcu1K5duyTdmy2zX79+2rZtm1atWiU7Ozs1a9bMnDDHxcWpZs2aOnv2rH766Sft3r1b7777rpKTkxUSEqI6depo+vTpFseZPn26OnbsKDs7vm4BAAAeR2hoqAICArRq1SpzWUxMjDZv3qzKlStLkipXrqwbN25o+/bt5jqrV69WcnKyKlWqlO0xSwwvB2AjU6dO1SuvvCJJql+/vqKjo/Xbb7+pVq1a+uijj9SmTRsNHz7cXL906dKSpMOHD2vevHlauXKleRKNAgUKZPj4iYmJ+uabb+Tn52cua9GihUWdadOmyc/PTwcOHFDJkiU1Z84cXb58WVu3bpWPj48kqVChQub6Xbt21RtvvKExY8bIyclJO3bs0N69e/W///0vw/EBAAA8jeLi4hQVFWV+fvz4ce3atUs+Pj7Kly+f+vTpow8//FCFCxdWaGioBg8erDx58qhp06aSpOLFi6t+/fp67bXX9MUXX+jOnTvq2bOn2rRpY7NbGel6AZDtDh06pC1btqht27aS7k1u0bp1a/MQ8V27dql27dpp7rtr1y7Z29urZs2ajxVD/vz5LRJuSTpy5Ijatm2rAgUKyMPDQyEhIZKkU6dOmY9dpkwZc8L9oKZNm8re3l4//vijpHtD3Z999llzOwAAAHi0bdu2qUyZMipTpowkqV+/fipTpoyGDBkiSXr33Xf11ltv6fXXX1eFChUUFxenZcuWmW8XlKTZs2erWLFiql27tho2bKhq1arpyy+/tMn5SPR0A7CBqVOnKikpyeLXRsMw5OTkpM8//1wuLi4P3fdR2yTJzs7OPEw9xZ07d1LVc3V1TVXWpEkT5c+fX1999ZXy5Mmj5ORklSxZUomJiek6tqOjo9q3b6/p06erefPmmjNnjj777LNH7gMAAIC/1KpVK9XfcvczmUwaMWKERowY8dA6Pj4+mjNnjjXCyxR6ugFkq6SkJH3zzTf69NNPtWvXLvNj9+7dypMnj7777juVKlXK4l6d+4WHhys5OVm//fZbmtv9/PwUGxur+Ph4c1nKPduPcvXqVR06dEjvv/++ateureLFi+v69esWdUqVKqVdu3bp2rVrD22na9eu+vXXXzVp0iQlJSWpefPmf3tsAAAA/HvR0w0gWy1evFjXr19Xly5d5OnpabGtRYsWmjp1qv773/+qdu3aKliwoNq0aaOkpCT98ssveu+99xQSEqIOHTqoc+fOGj9+vEqXLq2TJ0/q0qVLatWqlSpVqqScOXPqP//5j3r16qXNmzenmhk9Ld7e3sqVK5e+/PJLBQYG6tSpUxowYIBFnbZt2+rjjz9W06ZNFRkZqcDAQO3cuVN58uQxT95RvHhxPfPMM3rvvffUuXPnv+0dBwAAwL8bPd0AstXUqVNVp06dVAm3dC/p3rZtm3x8fDR//nz99NNPioiI0HPPPactW7aY602ePFkvvfSS3nzzTRUrVkyvvfaauWfbx8dHs2bN0i+//KLw8HB99913GjZs2N/GZWdnp++//17bt29XyZIl1bdvX/33v/+1qOPo6KgVK1Yod+7catiwocLDwzVy5EjZ29tb1OvSpYsSExPVuXPnTFwhAAAA/JuYjEcNmP8XOnPmjIKDg3X69GkFBQXZOpw0hQxYYusQngonRjaydQj4l/rggw80f/587dmzx9ahZAu+s7IP31tA1uB7K/u4Fx/w95Xw2PZ22GvrENL0T8i9sgM93QCQReLi4rRv3z59/vnneuutt2wdDgAAAJ4AJN0AkEV69uypcuXKqVatWgwtBwAAgCQmUgOALDNjxox0TdoGAACApwc93QAAAAAAWMkT0dP9zaYTmvLbMV2OS1DxQA8Nf6GEIoK90qzbesombT6eeo3cZ4v6aXqnilaOFAAAAACA9LN50v3z7nP6cPFBfdispMoEe2nahuNqP3WzVr9TS75uTqnqT3m1nBLvJpuf37h5Rw0++10NwwOzM2wAAAAAAP6WzYeXf73+uNpUDFar8sEq7O+uj5qGy8XRXvO2nU6zvldOR+V2dzY/fj9yRS4O9mpUiqQbAAAAAPBksWlPd2JSsvadjdabtQqay+zsTKpayFc7Tt5IVxvztp5Wk9KByumY9qkkJCQoISHB/Dw2NvaxYgYAAAAAIL1s2tN9/Wai7iYbqYaR+7k56XJcwkP2+suu0zd06GKsWlfI99A6kZGR8vT0ND/CwsIeO24AAAAAANLD5sPLH8fcradVLMD9oZOuSdLAgQMVHR1tfhw4cCD7AgTwVNqwYYPCw8Pl4OCgpk2bpmufYcOGKSIiwqpx2dLtU3t0clRjJd+Os3UoAAAA2cqmw8u9czrK3s6kKw/0al+OS5BfGpOo3e9mYpIW7z6nvnWLPLKek5OTnJz+aismJibzAQP/EOEzw7P1eHs77M1Q/cuXL2vIkCFasmSJLl68KG9vb5UuXVpDhgxR1apVrRRl9unXr58iIiK0dOlSubm5ZUmbJ06cUGhoaJrbNm3apGeeeSZLjgMAAICsZdOk2zGHnUrm9dTGqCuqVyJAkpScbGhj1FW1r5L/kfsu2XNeCXeT1axM3uwIFUAWatGihRITEzVz5kwVKFBAFy9e1KpVq3T16lVbh5Yljh49qjfeeENBQUFZ3vavv/6qEiVKWJTlypUry48DAACArGHz4eVdq4Xqu62ntWD7GUVditWgRft0MzFJLcsFS5L6zd2lUcv+TLXfvG2n9XyYv7xdHbM7ZACP4caNG/r99981atQoPfvss8qfP78qVqyogQMH6oUXXpB0r1fXZDJp165dFvuZTCatXbvWXLZ//341btxYHh4ecnd3V/Xq1XX06FHz9mnTpqlEiRJycnJSYGCgevbsadFe165d5efnJw8PDz333HPavXu3efvu3bv17LPPyt3dXR4eHipXrpy2bdsmSTp58qSaNGkib29vubq6qkSJEvrll1/McV+9elWdO3eWyWTSjBkzNGPGDHl5eVlch0WLFslkMmX4+uXKlUsBAQEWDwcHBxmGoTp16qhevXoyDEOSdO3aNQUFBWnIkCGSpLt376pLly4KDQ2Vi4uLihYtqs8++8yi/Y4dO6pp06b6+OOP5e/vLy8vL40YMUJJSUnq37+/fHx8FBQUpOnTp5v3SYq+qJOjGiv+wG+68O07OvlJM52b+qZun3r0CIjbZ/brwux3derT5jozqaOu/TpFyYm3zdtjdyzR2S9f08lPmun0hFd0+cePM3y9AAAAbM3m63Q3KZ1H1+ITNXblYV2OTVDxPB6a2bmi/NzvDQk/e+NWqj9Mj16O09YT1/Vtl4q2CBnAY3Bzc5Obm5sWLVqkZ555xuL2j4w4e/asatSooVq1amn16tXy8PDQhg0blJSUJEmaPHmy+vXrp5EjR6pBgwaKjo7Whg0bzPu3bNlSLi4uWrp0qTw9PTVlyhTVrl1bhw8flo+Pj9q1a6cyZcpo8uTJsre3165du+Tg4CBJ6tGjhxITE7Vu3Tq5urrqwIEDcnNzU3BwsM6fP6+iRYtqxIgRat26tTw9PTV37tzHv3B/w2QyaebMmQoPD9f48ePVu3dvvfHGG8qbN6856U5OTlZQUJDmz5+vXLlyaePGjXr99dcVGBioVq1amdtavXq1goKCtG7dOm3YsEFdunTRxo0bVaNGDW3evFlz585Vt27dVLduXYve/Otrp8u79mvKlSufYrb+qEs/jFDeN6bK3sUjVbx3rp/XpXlD5VX9VeVq0Ft3b8bo+q9f6NrKL+TbqI8Szh/RtV+nyLfx23LKW1zJt2N1+/R+q19HAACArGbzpFuSOlQJUYcqIWlum9utcqqygn5uOjGykZWjAmANOXLk0IwZM/Taa6/piy++UNmyZVWzZk21adNGpUqVSnc7EydOlKenp77//ntzMlykyF9zPHz44Yd6++231bt3b3NZhQoVJEnr16/Xli1bdOnSJXPS/8knn2jRokVasGCBXn/9dZ06dUr9+/dXsWLFJEmFCxc2t3Pq1Cm1aNFC4eH37p0vUKCAeVtAQIBMJpM8PT0VEBCQ0cvzt6pUqSI7O8tBSnFx9yYny5s3r6ZMmaL27dvrwoUL+uWXX7Rz507lyHHvq97BwUHDhw837xcaGqpNmzZp3rx5Fkm3j4+Pxo8fLzs7OxUtWlSjR4/WzZs39Z///EfSvQkqR44cqfXr16tNmzbm/dzLNpZr0Xv35PvU66Fbx3cobs8KeVZ6KdV5xPwxX65hteRR4cV7sfnklXed13VxzkDlqvem7sZclsnBWS4FK8jOKafkmVuO/gVTtQMAAPCkeyKSbgBPlxYtWqhRo0b6/fff9ccff2jp0qUaPXq0vv76a3Xs2DFdbezatUvVq1c3J9z3u3Tpks6dO6fatWunue/u3bsVFxeX6l7oW7dumYen9+vXT127dtW3336rOnXqqGXLlipY8F7S16tXL3Xv3l0rVqxQnTp11KJFiwz9YPA45s6dq+LFiz90e8uWLfXjjz9q5MiRmjx5ssWPBdK9HyumTZumU6dO6datW0pMTEw1a3qJEiUsEnt/f3+VLFnS/Nze3l65cuXSpUuXLPZzylvM/G+Tnb0cAwrpzpUzacaZeOm4Ei8fV/yBtfeVGpKRrKQbF+UcEqEcnrl1dkpXuRQoJ+fQsspZpLLsHJwfeu4AAABPIpJuADbh7OysunXrqm7duho8eLC6du2qoUOHqmPHjuaEL+XeZEm6c+eOxf4uLi4PbftR26R7PcOBgYEW94enSLn3etiwYXr55Ze1ZMkSLV26VEOHDtX333+vZs2aqWvXrqpXr56WLFmiFStWKDIyUp9++qneeuutNI9nZ2dncS5pnU96BQcHq1ChQg/dfvPmTW3fvl329vY6cuSIxbbvv/9e77zzjj799FNVrlxZ7u7u+u9//6vNmzdb1HvwhwyTyZRmWXJycqbOQZKSE2/JPaKB3Ms1SbUth4efTPYOCuz4mW6f2qvbx3coev1sRW+Yo8D2Y2XnnDUzwgMAAGQHm0+kBgCSFBYWpvj4eEmSn5+fJOn8+fPm7fdPqiZJpUqV0u+//55m8uru7q6QkBCtWrUqzWOVLVtWFy5cUI4cOVSoUCGLh6+vr7lekSJF1LdvX61YsULNmze3mDwsODhYb7zxhhYuXKi3335bX3311UPPzc/PT7GxsebzS+t8ssrbb78tOzs7LV26VOPHj9fq1avN2zZs2KAqVarozTffVJkyZVSoUCGLieceV8K5vya9NJLvKvHCUTn4pj2Du2NAQd25ckoO3nlSPUz29xJ8k529XEIi5P1sZwV2+lxJ0Zd0++SeLIsXAAAgO5B0A8hWV69e1XPPPadZs2Zpz549On78uObPn6/Ro0frxRfv3d/r4uKiZ555RiNHjtTBgwf122+/6f3337dop2fPnoqJiVGbNm20bds2HTlyRN9++60OHTok6V5P9aeffqrx48fryJEj2rFjhyZMmCBJqlOnjipXrqymTZtqxYoVOnHihDZu3KhBgwZp27ZtunXrlnr27Km1a9fq5MmT2rBhg7Zu3Woe1t2nTx8tX75cx48f144dO7RmzZpHDvmuVKmScubMqf/85z86evSo5syZoxkzZmT6+l24cMHicfv2vRm/lyxZomnTpmn27NmqW7eu+vfvrw4dOuj69euS7t2Xvm3bNi1fvlyHDx/W4MGDtXXr1kzFkZbYHUt08/BG3bl6WtdWTFZyQpzcwuumWdez0ktKOPunrq2crMSLx3Tn2lndPPKHrq2cLEm6GbVFMdt+UuLFY0qKvqT4/aslw1AOH5aJBAAA/ywMLweQrdzc3FSpUiWNHTtWR48e1Z07dxQcHKzXXnvNPFGXdG+5ry5duqhcuXLmybyef/558/ZcuXJp9erV6t+/v2rWrCl7e3tFRESoatV7E3l16NBBt2/f1tixY/XOO+/I19dXL710b0Ivk8mkX375RYMGDVKnTp10+fJlBQQEqEaNGvL395e9vb2uXr2q9u3b6+LFi/L19VXz5s3Nk5DdvXtXPXr00JkzZ+Th4aH69etr7NixDz1nHx8fzZo1S/3799dXX32l2rVra9iwYXr99dczfP3q1KmTquy7775T7dq11aVLFw0bNkxly5aVJA0fPlwrVqzQG2+8YZ5xfOfOnWrdurVMJpPatm2rN998U0uXLs1wHGnxrtlR0X8sUOKlY3LwyqPczQfLPqdnmnUdc4fK/+VI3Vj3rS7Mee9eQu0VINfiNSRJds6uunl4o6I3zJGRdEc5vAPl26S/HP3yZ0msAAAA2cVkPHij4b/cmTNnFBwcrNOnT1ssdfMkCRmwxNYhPBWYAR/IGkHdp+nsF10U2HG8HP0L/P0OyDS+t4Cswd9a2ce9+ABbh/BU2Nthr61DSNM/IffKDgwvBwAAAADASki6AQAAAACwEu7pBgA8lhye/sr/3mJbhwEAAPBEoqcbAAAAAAArIekGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACsh6QYAAAAAwEpIugHgCXThwgXVrVtXrq6u8vLyStc+a9eulclk0o0bN6wamy2dHNVYNw9vsnUYAAAA6cY63cC/0MFixbP1eMX/PJih+rVq1VJERITGjRtnUT5jxgz16dPnX500ptfYsWN1/vx57dq1S56enlnWbkhIiE6ePJmqPDIyUgMGDMiy4wAAAOAekm4AeAIdPXpU5cqVU+HChbO87REjRui1116zKHN3d8/y4wAAAIDh5QCeYB07dlTTpk31ySefKDAwULly5VKPHj10584dc51JkyapcOHCcnZ2lr+/v1566SXztpCQkFS96RERERo2bJj5+Y0bN9StWzf5+/vL2dlZJUuW1OLFi83bN2zYoFq1ailnzpzy9vZWvXr1dP36dUlScnKyIiMjFRoaKhcXF5UuXVoLFiww73v9+nW1a9dOfn5+cnFxUeHChTV9+nRJUmJionr27KnAwEA5Ozsrf/78ioyMNMf9ww8/6JtvvpHJZFLHjh114sQJmUwm7dq1yyJ2k8mktWvXZui6uru7KyAgwOLh6uoq6V5CnidPHl29etVcv1GjRnr22WeVnJwsSRozZozCw8Pl6uqq4OBgXV0xScmJt8z14/b+qlPjWutm1Bad/aqbTn3aQpd//FjJd24rbu8qnZncWafHtda1X6fISL5r3u/M5M66seE7Xf5ptE6NaaEzE9srdsdfr0VakmIu6/KikTo1rrVOf9ZGl374QEnRF83bb5/ao/Pf9NWpMS10alxrXZjVX0nRlzJ0vQAAAB4HPd0Anmhr1qxRYGCg1qxZo6ioKLVu3VoRERF67bXXtG3bNvXq1UvffvutqlSpomvXrun3339Pd9vJyclq0KCBYmNjNWvWLBUsWFAHDhyQvb29JGnXrl2qXbu2OnfurM8++0w5cuTQmjVrdPfuvUQxMjJSs2bN0hdffKHChQtr3bp1euWVV+Tn56eaNWtq8ODBOnDggJYuXSpfX19FRUXp1q17yen48eP1008/ad68ecqXL59Onz6t06dPS5K2bt2q9u3by8PDQ5999plcXFzMib61DRo0SMuWLVPXrl31448/auLEidq4caN2794tO7t7v9Pa2dlp/PjxCg0N1bFjx1SvZQddXztduZ5/09yOcSdBsdt/lt8L7yo58ZYu//ixLi/8SHbObsrdcpiSblzQ5UUfyylvcbkWr2HeL2bLQnlWbiWvau106/gOXfv1S+XwziuX0DKpYjXuJunSvCFyzFNMAe1GyWSy141N3+vivKHK03mCZLLTpYUfyb10Pfk2eVe6m6SE84clk/WvIwAAQAqSbgBPNG9vb33++eeyt7dXsWLF1KhRI61atUqvvfaaTp06JVdXVzVu3Fju7u7Knz+/ypRJnZw9zK+//qotW7bo4MGDKlKkiCSpQIEC5u2jR49W+fLlNWnSJHNZiRIlJEkJCQn6+OOP9euvv6py5crmfdevX68pU6aoZs2aOnXqlMqUKaPy5ctLuteDneLUqVMqXLiwqlWrJpPJpPz585u3+fn5ycnJSS4uLgoICJCkLE2633vvPb3//vsWZUuXLlX16tVlb2+vWbNmKSIiQgMGDND48eP19ddfK1++fOa6ffr0Mf87JCREXtVf0bUVkyySbiUnyef5N+XgHShJylm0iuL3r1FQz1myc3SRo28+Oecrpdun9lgk3U55w+T5TEtJkoNPXiWcOaCYbYvSTLrj//xdhmEoV4NeMpnuZdK+Dfvo9Lg2un1qrxwDCstIiJdLwQrmOBx8gx/v4gEAAGQQSTeAJ1qJEiXMPc+SFBgYqL1790qS6tatq/z586tAgQKqX7++6tevr2bNmilnzpzpanvXrl0KCgoyJ9xpbW/ZsmWa26KionTz5k3VrVvXojwxMdGc+Hfv3l0tWrTQjh079Pzzz6tp06aqUqWKpHtD5+vWrauiRYuqfv36aty4sZ5//vl0xf24+vfvr44dO1qU5c2b1/zvAgUK6JNPPlG3bt3UunVrvfzyyxZ1f/31V0VGRurPP/9UTEyM4m8nykhKVPKd27JzcJYkmRyczImuJNnn9FYOD3/ZObr8Vebqpbs3oy3adspbLNXzmG0/pXkedy4dV9L1czo91vI1MpISlXTjglxCy8q1ZB1dnDdELiERcg6JUM5i1ZXDzedvrhAAAEDWIekGkO08PDwUHR2dqvzGjRupZup2cHCweG4ymcz3Fru7u2vHjh1au3atVqxYoSFDhmjYsGHaunWrvLy8ZGdnJ8MwLPa//35wFxcXPcqjtsfFxUmSlixZYpGwSpKTk5MkqUGDBjp58qR++eUXrVy5UrVr11aPHj30ySefqGzZsjp+/LiWLl2qX3/9Va1atVKdOnUs7gm/X8rQ7vvP5/5zyQhfX18VKlTokXXWrVsne3t7nThxQklJScqR495/FydOnFDjxo3VvXt3ffTRR/Lx8VGVPhN1del46W6SlPJy2T3w34tJ0n0/npgLH3h9MiI58ZYcAwrJt8k7qbbZ57z3PvJt1Ece5Zvo1rHtunnwd934fZb8W32QKrkHAACwFiZSA5DtihYtqh07dqQq37Fjx0N7nR8mR44cqlOnjkaPHq09e/boxIkTWr16taR7w7TPnz9vrhsTE6Pjx4+bn5cqVUpnzpzR4cOH02y7VKlSWrVqVZrbwsLC5OTkpFOnTqlQoUIWj+Dgv4Yw+/n5qUOHDpo1a5bGjRunL7/80rzNw8NDrVu31ldffaW5c+fqhx9+0LVr19I8np+fnyRZnM/9k6plpblz52rhwoVau3atTp06pQ8++MC8bfv27UpOTtann36qZ555RkWKFFFSXNoxZ0bCuT8feH5IDrmC0qzr6F9QSdfPyT6nlxy881g87JxcLep5Vm6lgFc/kYNvPsUf/C3L4gUAAPg79HQDyHbdu3fX559/rl69eqlr165ycnLSkiVL9N133+nnn39OdzuLFy/WsWPHVKNGDXl7e+uXX35RcnKyihYtKkl67rnnNGPGDDVp0kReXl4aMmSIxVD1mjVrqkaNGmrRooXGjBmjQoUK6c8//5TJZFL9+vU1cOBAhYeH680339Qbb7whR0dHrVmzRi1btpSvr6/eeecd9e3bV8nJyapWrZqio6O1YcMGeXh4qEOHDhoyZIjKlSunEiVKKCEhQYsXL1bx4vfWUB8zZowCAwNVpkwZ2dnZaf78+QoICJCXl1ea5+ri4qJnnnlGI0eOVGhoqC5dupTqvuz0io2N1YULFyzKcubMKQ8PD505c0bdu3fXqFGjVK1aNU2fPl2NGzdWgwYN9Mwzz6hQoUK6c+eOJkyYoCZNmmjDhg2K27k0U3GkJeHMQUVvXqCchSvr9omduvnneuV+aWiadV1L1FLMloW6tPADeVVrJ3t3X92NuaSbhzfJo2ILGclJitu9TDkLVZK9Wy7duXZGSdfPy61k7SyLFwAA4O+QdAPIdgUKFNC6des0aNAg1alTR4mJiSpWrJjmz5+v+vXrp7sdLy8vLVy4UMOGDdPt27dVuHBhfffdd+bJzgYOHKjjx4+rcePG8vT01AcffGDR0y1JP/zwg9555x21bdtW8fHxKlSokEaOHClJKlKkiFasWKH//Oc/qlixolxcXFSpUiW1bdtWkvTBBx/Iz89PkZGROnbsmLy8vFS2bFn95z//kSQ5Ojpq4MCBOnHihFxcXFS9enV9//33ku4NjR89erSOHDkie3t7VahQQb/88ot5GHlapk2bpi5duqhcuXIqWrSoRo8enan7wIcMGaIhQ4ZYlHXr1k2TJ09Wx44dVbFiRfXs2VOSVK9ePXXv3l2vvPKKdu3apdKlS2vMmDEaNWqUBg4cqBo1asirZgddXTImw3GkxaNiMyWej1L0hu9k55hT3s91lUuBcmnWtXNwVsDLo3T9t+n3liRLvKUc7rnknL+07JxyykhK0J2rZ3R532rdvRUje1cfuZdpJLeI9L/HAAAAHpfJePCGx3+5M2fOKDg4WKdPn1ZQUNpDFm0tZMASW4fwVDgxspGtQwD+FbLqO+vM5M7yKP+iPCq8mCXt/RvxvQVkDf7Wyj7uxQfYOoSnwt4Oe20dQpr+CblXduCebgAAAAAArISkGwAAAAAAK+GebgDAEyGo+zRbhwAAAJDl6OkGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKSbgAAAAAArISkGwAAAAAAKyHpBgAAAADASki6AQAAAACwEpJuAAAAAACshKQbAAAAAAArIekGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKSbgAAAAAArCSHrQP4ZtMJTfntmC7HJah4oIeGv1BCEcFeD60ffeuOPll+SMv2X1D0zTvK6+2iIY3D9Gyx3NkXNAAAAAAA6WDTpPvn3ef04eKD+rBZSZUJ9tK0DcfVfupmrX6nlnzdnFLVT0xK1qtTNyuXq6Mmtysrfw9nnb1xSx7ODjaIHgAAAACAR7Np0v31+uNqUzFYrcoHS5I+ahqu1X9e0rxtp/VmrUKp6s/bdlo3bt7RD92ryMH+3sj4YJ+c2RozAAAAAADpZbOkOzEpWfvORuvNWgXNZXZ2JlUt5KsdJ2+kuc+vBy+qbD4vDfnfPq08cFE+ro56MSKv3qhZUPZ2pmyKHAAAAACA9LFZ0n39ZqLuJhuphpH7uTnp6OX4NPc5de2mNl6/paYReTS9Y0WduBqvwf/bpzt3k9WnTpE090lISFBCQoL5eWxsbNadBAAAAAAAj/CPmr3cMCRfV0dFNi+l8CBPNSmdRz2fLaTZm089dJ/IyEh5enqaH2FhYdkYMQAAAADgaWazpNs7p6Ps7Uy6EpdgUX45LkF+aUyiJkl+7k4K9XO1GEpeMLebLscmKDEpOc19Bg4cqOjoaPPjwIEDWXcSAAAAAAA8gs2SbsccdiqZ11Mbo66Yy5KTDW2Muqqy+b3S3Kd8fm+duHJTycmGuez45XjldneSY460T8XJyUkeHh7mh7u7e5aeBwAAAAAAD2PT4eVdq4Xqu62ntWD7GUVditWgRft0MzFJLcvdm82839xdGrXsT3P9V57Jr+hbdzT85/06djlOq/+8qElro9S+cn5bnQIAAAAAAA9l06S7Sek8GtSwuMauPKyGn63XgfMxmtm5ovzc7w0vP3vjli7F/DX8PI+Xi2Z2rqjdZ6JV/7PfNeynA+pUNVTd01heDAAAAADwz3H37l0NHjxYoaGhcnFxUcGCBfXBBx/IMP4a6WwYhoYMGaLAwEC5uLioTp06OnLkiA2j/ns2XadbkjpUCVGHKiFpbpvbrXKqsnL5vbWoR1UrRwUAAAAAyE6jRo3S5MmTNXPmTJUoUULbtm1Tp06d5OnpqV69ekmSRo8erfHjx2vmzJkKDQ3V4MGDVa9ePR04cEDOzs42PoO02TzpBgAAAABg48aNevHFF9WoUSNJUkhIiL777jtt2bJF0r1e7nHjxun999/Xiy++KEn65ptv5O/vr0WLFqlNmzY2i/1R/lFLhgEAAAAA/lliY2MVExNjfiQkJKRZr0qVKlq1apUOHz4sSdq9e7fWr1+vBg0aSJKOHz+uCxcuqE6dOuZ9PD09ValSJW3atMn6J5JJ9HQDAAAAAKwmLCzM4vnQoUM1bNiwVPUGDBigmJgYFStWTPb29rp7964++ugjtWvXTpJ04cIFSZK/v7/Ffv7+/uZtTyKSbgAAAACA1Rw4cEB58+Y1P3dyckqz3rx58zR79mzNmTNHJUqU0K5du9SnTx/lyZNHHTp0yK5wsxxJNwAAAADAatzd3eXh4fG39fr3768BAwaY780ODw/XyZMnFRkZqQ4dOiggIECSdPHiRQUGBpr3u3jxoiIiIqwSe1bgnm4AAAAAgM3dvHlTdnaWKaq9vb2Sk5MlSaGhoQoICNCqVavM22NiYrR582ZVrpx65asnBT3dAAAAAACba9KkiT766CPly5dPJUqU0M6dOzVmzBh17txZkmQymdSnTx99+OGHKly4sHnJsDx58qhp06a2Df4RSLoBAAAAADY3YcIEDR48WG+++aYuXbqkPHnyqFu3bhoyZIi5zrvvvqv4+Hi9/vrrunHjhqpVq6Zly5Y9sWt0SyTdAAAAAIAngLu7u8aNG6dx48Y9tI7JZNKIESM0YsSI7AvsMXFPNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAIGnZsmVav369+fnEiRMVERGhl19+WdevX89UmyTdAAAAAABI6t+/v2JiYiRJe/fu1dtvv62GDRvq+PHj6tevX6bazJGVAQIAAAAA8E91/PhxhYWFSZJ++OEHNW7cWB9//LF27Nihhg0bZqpNeroBAAAAAJDk6OiomzdvSpJ+/fVXPf/885IkHx8fcw94RtHTDQAAAACApGrVqqlfv36qWrWqtmzZorlz50qSDh8+rKCgoEy1SU83AAAAAACSPv/8c+XIkUMLFizQ5MmTlTdvXknS0qVLVb9+/Uy1SU83AAAAAACS8uXLp8WLF6cqHzt2bKbbpKcbAAAAAID/d/ToUb3//vtq27atLl26JOleT/f+/fsz1R5JNwAAAAAAkn777TeFh4dr8+bNWrhwoeLi4iRJu3fv1tChQzPVJkk3AAAAAACSBgwYoA8//FArV66Uo6Ojufy5557TH3/8kak2SboBAAAAAJC0d+9eNWvWLFV57ty5deXKlUy1SdINAAAAAIAkLy8vnT9/PlX5zp07zTOZZxRJNwAAAAAAktq0aaP33ntPFy5ckMlkUnJysjZs2KB33nlH7du3z1SbJN0AAAAAAEj6+OOPVaxYMQUHBysuLk5hYWGqUaOGqlSpovfffz9TbbJONwAAAAAAkhwdHfXVV19p8ODB2rdvn+Li4lSmTBkVLlw4022SdAMAAAAAcJ98+fIpX758WdIWSTcAAAAA4KnVr1+/dNcdM2ZMhtsn6QYAAAAAPLV27tyZrnomkylT7T8RSfc3m05oym/HdDkuQcUDPTT8hRKKCPZKs+78bafVf8EeizLHHHY6/GGDbIgUAAAAAPBvsmbNGqu2b/Ok++fd5/Th4oP6sFlJlQn20rQNx9V+6matfqeWfN2c0tzH3SmHVr1T0/zcpMz94gAAAAAAQFpOnz4tSQoODn6sdmy+ZNjX64+rTcVgtSofrML+7vqoabhcHO01b9vph+9kknK7O5sffu5pJ+cAAAAAAKRXUlKSBg8eLE9PT4WEhCgkJESenp56//33defOnUy1adOe7sSkZO07G603axU0l9nZmVS1kK92nLzx0P1uJt5V1ZGrlWwYKpHHU+/WL6oi/u7ZEDEAAAAA4N/qrbfe0sKFCzV69GhVrlxZkrRp0yYNGzZMV69e1eTJkzPcpk2T7us3E3U32Ug1jNzPzUlHL8enuU8BPzeNblFKxQLdFXs7SV+tO6YWkzZqRb8aCvR0SVU/ISFBCQkJ5uexsbFZexIAAAAAgH+FOXPm6Pvvv1eDBn/NGVaqVCkFBwerbdu2mUq6bT68PKPK5fdWi3JBKpHHU88UyKUvXi0nHzdHzdl8Ks36kZGR8vT0ND/CwsKyOWIAAAAAwD+Bk5OTQkJCUpWHhobK0dExU23atKfbO6ej7O1MuhKXYFF+OS5Bfg+ZRO1BDvZ2KpHHQyeu3kxz+8CBAy3WXTt79iyJNwDgHyl8ZritQ3gq7O2w19YhAABspGfPnvrggw80ffp0OTndy0kTEhL00UcfqWfPnplq06ZJt2MOO5XM66mNUVdUr0SAJCk52dDGqKtqXyV/utq4m2zozwuxerZo7jS3Ozk5mS+WJMXExDx+4AAAAACAf52dO3dq1apVCgoKUunSpSVJu3fvVmJiomrXrq3mzZub6y5cuDBdbdp8ybCu1UL19vzdCg/yUkSwp6auP6GbiUlqWe7etOz95u6Sv6ez3qtfTJL02a9HVCafl0JyuSrm9h1NWXdMZ6/fUpsKjzeNOwAAAADg6ebl5aUWLVpYlD3ukmE2T7qblM6ja/GJGrvysC7HJqh4Hg/N7FzRvAzY2Ru3ZDL9tQ539K07Grhwry7HJsjDxUHheT30Q/cqKszs5QAAAACAxzB9+vQsb9PmSbckdagSog5VQtLcNrdbZYvnQ5qEaUgT7skGAAAAADz5noikGwAAAAAAW7t69aqGDBmiNWvW6NKlS0pOTrbYfu3atQy3SdINAAAAAICkV199VVFRUerSpYv8/f0tbnXOLJJuAAAAAAAk/f7771q/fr155vKsYJdlLQEAAAAA8A9WrFgx3bp1K0vbJOkGAAAAAEDSpEmTNGjQIP3222+6evWqYmJiLB6ZwfByAAAAAAB0b53umJgYPffccxblhmHIZDLp7t27GW6TpBsAAAAAAEnt2rWTg4OD5syZw0RqAAAAAABkpX379mnnzp0qWrRolrXJPd0AAAAAAEgqX768Tp8+naVt0tMNAAAAAICkt956S71791b//v0VHh4uBwcHi+2lSpXKcJsk3QAAAAAASGrdurUkqXPnzuYyk8nERGoAAAAAADyu48ePZ3mbJN0AAAAAAEjKnz9/lreZ4aS76sjValU+WC+VD1JeL5csDwgAAAAAAFs6cOCATp06pcTERIvyF154IcNtZTjp7lwtVAu2n9H41UdUuUAutaoQrHol/OWUwz7DBwcAAAAA4Elx7NgxNWvWTHv37jXfyy3JvF53Zu7pzvCSYV2qhWpp7+r6X4+qKpTbTcN+2q+KH63SkP/t076z0RkOAAAAAACAJ0Hv3r0VGhqqS5cuKWfOnNq/f7/WrVun8uXLa+3atZlqM9P3dJfM66mSeT01qFFxfbvppEYu+1Oz/jipogEe6lQlRC3LB5l/DQAAAAAA4Em3adMmrV69Wr6+vrKzs5OdnZ2qVaumyMhI9erVSzt37sxwm5lOuu/cTdby/Rc0f9sZrY+6ojLBXmpVIVgXom9r9PJDWh91RePblsls8wAAAAAAZKu7d+/K3d1dkuTr66tz586paNGiyp8/vw4dOpSpNjOcdO87G635207rp93nZGcyqXnZvBrcOEyFcruZ69QrEaAXPl+fqYAAAAAAALCFkiVLavfu3QoNDVWlSpU0evRoOTo66ssvv1SBAgUy1WaGk+4XPl+vaoX99GHTcD1fwl8O9qlvCw/2cVGT0nkyFRAAAAAAALbw/vvvKz4+XpI0YsQINW7cWNWrV1euXLk0d+7cTLWZ4aR73bvPKsg75yPr5HTMoU9als5UQAAAAAAA2EK9evXM/y5UqJD+/PNPXbt2Td7e3pmesyzDs5dfjUvUzlPXU5XvPHVde87cyFQQAAAAAADY2uXLl1OV+fj4yGQyae/evZlqM8NJ95D/7dP56Nupyi/G3Nbg/+3PVBAAAAAAANhaeHi4lixZkqr8k08+UcWKFTPVZoaT7iOX4lQyj2eq8hJ5PBV1MTZTQQAAAAAAYGv9+vVTixYt1L17d926dUtnz55V7dq1NXr0aM2ZMydTbWY46XbMYafLcQmpyi/F3pa9HetyAwAAAAD+md59911t2rRJv//+u0qVKqVSpUrJyclJe/bsUbNmzTLVZoaT7uqF/TR62Z+KuX3HXBZ9645GLzuk6oX9MhUEAAAAAABPgkKFCqlkyZI6ceKEYmJi1Lp1awUEBGS6vQwn3YMaFtf56NuqOnK12ny5SW2+3KTqo1brclyCBjUqnulAAAAAAABPt7Nnz+qVV15Rrly55OLiovDwcG3bts283TAMDRkyRIGBgXJxcVGdOnV05MiRLDv+hg0bVKpUKR05ckR79uzR5MmT9dZbb6l169a6fj31hOLpkeGkO8DTWcv6VNfABsVVOLe7wvN6amiTElrep4byeLlkKggAAAAAwNPt+vXrqlq1qhwcHLR06VIdOHBAn376qby9vc11Ro8erfHjx+uLL77Q5s2b5erqqnr16un27dSTfWfGc889p9atW+uPP/5Q8eLF1bVrV+3cuVOnTp1SeHh4ptrM8Drd0r11uF+ulC9TBwQAAAAA4EGjRo1ScHCwpk+fbi4LDQ01/9swDI0bN07vv/++XnzxRUnSN998I39/fy1atEht2rR57BhWrFihmjVrWpQVLFhQGzZs0EcffZSpNjPc053iyMVYrT10SSsPXLR4AAAAAACQIjY2VjExMeZHQkLqibkl6aefflL58uXVsmVL5c6dW2XKlNFXX31l3n78+HFduHBBderUMZd5enqqUqVK2rRpU5bE+mDCncLOzk6DBw/OVJsZTrpPXb2p+uPW6flx69R5xla9/u02vf7tNnX7/wcAAAAAACnCwsLk6elpfkRGRqZZ79ixY5o8ebIKFy6s5cuXq3v37urVq5dmzpwpSbpw4YIkyd/f32I/f39/87bMatiwoaKjo83PR44cqRs3bpifX716VWFhYZlqO8PDy4f/vF/BPjk157VnVH3Uav2vZ1Vdv3lHHy45qEENmUgNAAAAAPCXAwcOKG/evObnTk5OadZLTk5W+fLl9fHHH0uSypQpo3379umLL75Qhw4drBrj8uXLLXrgP/74Y7Vq1UpeXl6SpKSkJB06dChTbWe4p3vHqevqV7eIfFwdZWcyyWQyqUKIj96rV1TDftqfqSAAAAAAAP9O7u7u8vDwMD8elnQHBgam6k0uXry4Tp06JUnmZbsuXrS8rfnixYuPtaSXdO9+8Uc9fxwZTrrvJhtyc7rXQe7t6qiLMfdmicvr7aJjV+KyLDAAAAAAwNOjatWqqXqTDx8+rPz580u6N6laQECAVq1aZd4eExOjzZs3q3Llytkaa0ZkeHh50QB3HTgfo2CfnIoI9tKU347J0d5Oc7acUj6fnNaIEQAAAADwL9e3b19VqVLFPLR7y5Yt+vLLL/Xll19Kkkwmk/r06aMPP/xQhQsXVmhoqAYPHqw8efKoadOmj3Vs0/+P4n6wLCtkOOnu+Vxh3UpMkiT1q1tEnWduVcspm+Sd01Gfty2TJUEBAAAAAJ4uFSpU0I8//qiBAwdqxIgRCg0N1bhx49SuXTtznXfffVfx8fF6/fXXdePGDVWrVk3Lli2Ts7PzYx3bMAx17NjRPPT99u3beuONN+Tq6ipJD51xPT0ynHTXLOJn/neIr6tWv11LN24mytPFIct+CQAAAAAAPH0aN26sxo0bP3S7yWTSiBEjNGLEiCw97oMTtb3yyiup6rRv3z5TbWco6b5zN1nFBi/TL72qq2iAu7ncK6djpg4OAAAAAICtTZ8+3WptZ2giNQd7O+Xxctbd5KybyQ0AAAAAgH+rDM9e3vPZQvrv8j9142aiNeIBAAAAAOBfI8P3dM/ceFInr8ar4serFOTlIhdHe4vtS3pVz7LgAAAAAAD4J8tw0v18CX9rxAEAAAAAwL9OhpPuPnWKWCMOAAAAAACyXdmyZbVq1Sp5e3trxIgReuedd5QzZ84saz/D93QDAAAAAPBvcfDgQcXHx0uShg8frri4uCxtP8M93aEDl+hRq3Efi2z0GOEAAAAAAJB9IiIi1KlTJ1WrVk2GYeiTTz6Rm5tbmnWHDBmS4fYznHRPeaWcxfOkZEP7z0Xrh+1n1bdu4QwHAAAAAACArcyYMUNDhw7V4sWLZTKZtHTpUuXIkTpVNplM2ZN0P18iIFVZw/BAFfF318+7z6t1hXwZDgIAAAAAAFsoWrSovv/+e0mSnZ2dVq1apdy5c2dZ+1l2T3eZYG9tPHolq5oDAAAAACBbJScnZ2nCLWWipzstt+/c1fSNxxXg4ZwVzQEAAAAAYBNHjx7VuHHjdPDgQUlSWFiYevfurYIFC2aqvQwn3aWGLZfJ9NdUaoZhKD7xrlwc7DW2dUSmgvhm0wlN+e2YLsclqHigh4a/UEIRwV5/u99Pu8+p13c7VTfMX1+1L5+pYwMAAAAAIEnLly/XCy+8oIiICFWtWlWStGHDBpUoUUI///yz6tatm+E2M5x0D24cZpF025kkH1dHlQn2lmdOhwwH8PPuc/pw8UF92KykygR7adqG42o/dbNWv1NLvm5OD93v9LWb+njJQVUM8cnwMQEAAAAAeNCAAQPUt29fjRw5MlX5e++9lz1Jd8vywRk+yKN8vf642lQMVqv/b/ejpuFa/eclzdt2Wm/WKpTmPneTDfWZu0t96xbWluPXFXP7TpbGBAAAAAB4+hw8eFDz5s1LVd65c2eNGzcuU21meCK1edtOa8me86nKl+w5rwXbz2SorcSkZO07G62qhXz/CsjOpKqFfLXj5I2H7vfZqiPK5erITOkAAAAAgCzj5+enXbt2pSrftWtXpidYy3BP9+S1R/VRs5KpynO5Oeo/C/fqpXJB6W7r+s1E3U02Ug0j93Nz0tHL8Wnus/XENc3belq/9K6ermMkJCQoISHB/Dw2Njbd8QEAAAAAnh6vvfaaXn/9dR07dkxVqlSRdO+e7lGjRqlfv36ZajPDSffZG7cU7J0zVXleLxedvXErU0GkV1xCkvrO3aXIFuHycXVM1z6RkZEaPny4VeMCAAAAAPzzDR48WO7u7vr00081cOBASVKePHk0bNgw9erVK1NtZjjp9nV11J8XYhXsY5l4HzwfI++c6UuEU3jndJS9nUlX4hIsyi/HJcgvjUnUTl6N15nrt9R15jZzWbJhSJIK/ucXrX67pvLncrXYZ+DAgRa/SJw9e1ZhYWEZihMAAAAA8O9nMpnUt29f9e3b1zxK2t3d/bHazHDS3SQij4b9tF+uTvaqFJpLkrT52FUN//mAmpQOzFBbjjnsVDKvpzZGXVG9EgGSpORkQxujrqp9lfyp6hf0c9PyPjUsyj5ZcUjxCUka2qSEAj1dUu3j5OQkJ6e/EviYmJgMxQgAAAAAePo8brKdIsNJ99t1i+rM9Vtq9/Vm5bC7t3RYsiE1L5NX/esVy3AAXauF6u35uxUe5KWIYE9NXX9CNxOT1LLcvdnM+83dJX9PZ71Xv5icHexVNMDyxD2c7y1T9mA5AAAAAAC2luGk2zGHnSa+XFbHr8TrwLkYOTvYqWiAu4LSuM87PZqUzqNr8Ykau/KwLscmqHgeD83sXFF+7vd6p8/euGWxLjgAAAAAAP8UGU66U4T6uirU1/XvK6ZDhyoh6lAlJM1tc7tVfuS+n7YqnSUxAAAAAACQ1TK8Tvcb327X5LVHU5V/8dtRvTl7e5YEBQAAAABAdrpz545q166tI0eOZGm7GU66t5y4pmeL+aUqr1XUT1uOX8uSoAAAAAAAyE4ODg7as2dPlreb4aQ7PiFJDvapd8thZ6fY20lZEhQAAAAAANntlVde0dSpU7O0zQzf010swF2Ld59X7zqFLcp/3n1Ohf3dsiwwAAAAAACyU1JSkqZNm6Zff/1V5cqVk6ur5TxmY8aMyXCbGU6633qusN6YtV0nr8WrSkFfSdLGqCv63+5zmtSubIYDAAAAAADgSbBv3z6VLXsvrz18+LDFtsyuqpXhpLtOmL++bF9OE9cc1dK9++TsYKfigR6a07WSvHI6ZioIAAAAAABsbc2aNVneZqaWDHuumL+eK+YvSYq9fUc/7T6nj385qL1no3UsslGWBggAAAAAQHaKiorS0aNHVaNGDbm4uMgwjOzr6U6x+dhVzd12Wsv2XZC/h7PqlQjQiBdLZrY5AAAAAABs6urVq2rVqpXWrFkjk8mkI0eOqECBAurSpYu8vb316aefZrjNDM1efin2tiatjVKt/65Rjzk75O6UQ4lJyfry1XIa0KCYSgd7ZTgAAAAAAACeBH379pWDg4NOnTqlnDlzmstbt26tZcuWZarNdPd0d5mxVVuOX9OzxXJrSJMw1SySW/Z2Js3efCpTBwYAAAAA4EmyYsUKLV++XEFBQRblhQsX1smTJzPVZrqT7rWHL6tjlRC98kx+hfq6/v0OAAAAAAD8g8THx1v0cKe4du2anJycMtVmuoeXz3+jsuITktRkwnq9OHGDZm48oWvxiZk6KAAAAAAAT5rq1avrm2++MT83mUxKTk7W6NGj9eyzz2aqzXT3dJfN562y+bw1pEmYFu8+r3nbTuvDJQeUbBj6/cgVBXq5yM0p0/OyAQAAAABgU6NHj1bt2rW1bds2JSYm6t1339X+/ft17do1bdiwIVNtZjhLzumYQ60qBKtVhWAdvRyneVtPa/JvRzVq2Z+qXthXX3eokKlAAAAAAACwpZIlS+rw4cP6/PPP5e7urri4ODVv3lw9evRQYGBgptp8rK7pgn5uGtiwuN6tX0y/Hryo+dtOP05zAAAAAADYlKenpwYNGpRl7WXJeHB7O5PqlQhQvRIBWdEcAAAAAAA2cf36dU2dOlUHDx6UJIWFhalTp07y8fHJVHsZWqcbAAAAAIB/q3Xr1ikkJETjx4/X9evXdf36dY0fP16hoaFat25dptpk5jMAAAAAACT16NFDrVu31uTJk2Vvby9Junv3rt5880316NFDe/fuzXCb9HQDAAAAACApKipKb7/9tjnhliR7e3v169dPUVFRmWqTpBsAAAAAAElly5Y138t9v4MHD6p06dKZapPh5QAAAACAp9aePXvM/+7Vq5d69+6tqKgoPfPMM5KkP/74QxMnTtTIkSMz1T5JNwAAAADgqRURESGTySTDMMxl7777bqp6L7/8slq3bp3h9km6AQAAAABPrePHj1u1fZJuAAAAAMBTK3/+/FZtn6QbAAAAAID/d+7cOa1fv16XLl1ScnKyxbZevXpluD2SbgAAAAAAJM2YMUPdunWTo6OjcuXKJZPJZN5mMplIugEAAAAAyKzBgwdryJAhGjhwoOzssmaFbdbpBgAAAABA0s2bN9WmTZssS7glkm4AAAAAACRJXbp00fz587O0TYaXAwAAAAAgKTIyUo0bN9ayZcsUHh4uBwcHi+1jxozJcJsk3QAAAAAA6F7SvXz5chUtWlSSUk2klhkk3QAAAAAASPr00081bdo0dezYMcva5J5uAAAAAAAkOTk5qWrVqlnaJkk3AAAAAACSevfurQkTJmRpmwwvBwAAAABA0pYtW7R69WotXrxYJUqUSDWR2sKFCzPcJkk3AAAAAACSvLy81Lx58yxtk6QbAAAAAABJ06dPz/I2uacbAAAAAAAroacbAAAAAABJoaGhj1yP+9ixYxluk6QbAAAAAABJffr0sXh+584d7dy5U8uWLVP//v0z1SZJNwAAAAAAurdkWFomTpyobdu2ZapN7ukGAAAAAOARGjRooB9++CFT+5J0AwAAAADwCAsWLJCPj0+m9mV4OQAAAAAAksqUKWMxkZphGLpw4YIuX76sSZMmZapNkm4AAAAAACQ1bdrU4rmdnZ38/PxUq1YtFStWLFNtknQDAAAAACBp6NChWd4m93QDAAAAAGAl9HQDAAAAAJ5qdnZ2Fvdyp8VkMikpKSnDbZN0AwAAAACeaj/++ONDt23atEnjx49XcnJyptom6QYAAAAAPNVefPHFVGWHDh3SgAED9PPPP6tdu3YaMWJEptp+IpLubzad0JTfjulyXIKKB3po+AslFBHslWbdZfvOa+KaozpxNV5Jdw2F+Lrqteqhal42KHuDBgAAAAD865w7d05Dhw7VzJkzVa9ePe3atUslS5bMdHs2T7p/3n1OHy4+qA+blVSZYC9N23Bc7adu1up3asnXzSlVfU8XR/V4tpAK5XaVg72dVh28pP4L9iiXm5NqFvGzwRkAAAAAAP7poqOj9fHHH2vChAmKiIjQqlWrVL169cdu1+azl3+9/rjaVAxWq/LBKuzvro+ahsvF0V7ztp1Os37lgrlUv2SACuV2V/5crupcLVTFAty17cS1bI4cAAAAAPBvMHr0aBUoUECLFy/Wd999p40bN2ZJwi3ZuKc7MSlZ+85G681aBc1ldnYmVS3kqx0nb/zt/oZhaOPRqzp2OV4DGvikWSchIUEJCQnm57GxsY8dNwAAAADg32PAgAFycXFRoUKFNHPmTM2cOTPNegsXLsxw2zbt6b5+M1F3k41Uw8j93Jx0OS7hIXtJMbfvKGzIMhUetFSdZmzV8BdKqHrhtIeWR0ZGytPT0/wICwvL0nMAAAAAAGS9kSNHymQyqU+fPuay27dvq0ePHsqVK5fc3NzUokULXbx48bGP1b59e7Vq1Uo+Pj4W+eODj8yw+T3dmeHmmEO/9Kqu+MQkbYy6qg+WHFCwT05VLpgrVd2BAweqX79+5udnz54l8QYAAACAJ9jWrVs1ZcoUlSpVyqK8b9++WrJkiebPny9PT0/17NlTzZs314YNGx7reDNmzHis/R/Fpkm3d05H2duZdOWBXu3LcQnyS2MStRR2diaF+LpKkkrk8VTUpThNWhuVZtLt5OQkJ6e/2oqJicmi6AEAAAAAWS0uLk7t2rXTV199pQ8//NBcHh0dralTp2rOnDl67rnnJEnTp09X8eLF9ccff+iZZ56xVciPZNPh5Y457FQyr6c2Rl0xlyUnG9oYdVVl83ulu51kw1BiUuYWKgcAAAAAWE9sbKxiYmLMj/vn3EpLjx491KhRI9WpU8eifPv27bpz545FebFixZQvXz5t2rTJKrFnBZvPXt61Wqi+23paC7afUdSlWA1atE83E5PUslywJKnf3F0atexPc/2Ja6L0+5HLOnX1pqIuxeqrdcf0486zalYmr61OAQAAAADwEGFhYRb3RUdGRj607vfff68dO3akWefChQtydHSUl5eXRbm/v78uXLiQ1WFnGZvf092kdB5di0/U2JWHdTk2QcXzeGhm54ryc783JPzsjVsymUzm+rcS72rwon06H31bzg72KujnqrGtI9SkdB5bnQIAAAAA4CEOHDigvHn/6iS9//bf+50+fVq9e/fWypUr5ezsnF3hWZ3Nk25J6lAlRB2qhKS5bW63yhbP36lXVO/UK5oNUQEAAAAAHpe7u7s8PDz+tt727dt16dIllS1b1lx29+5drVu3Tp9//rmWL1+uxMRE3bhxw6K3++LFiwoICLBG6FniiUi6AQAAAABPt9q1a2vv3r0WZZ06dVKxYsX03nvvKTg4WA4ODlq1apVatGghSTp06JBOnTqlypUrp9XkE4GkGwAAAABgc+7u7ipZsqRFmaurq3LlymUu79Kli/r16ycfHx95eHjorbfeUuXKlZ/Ymcslkm4AAAAAwD/E2LFjZWdnpxYtWighIUH16tXTpEmTbB3WI5F0AwAAAACeSGvXrrV47uzsrIkTJ2rixIm2CSgTbL5kGAAAAAAA/1Yk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlOWwdgCR9s+mEpvx2TJfjElQ80EPDXyihiGCvNOt+t+WUFu44o0MXYiVJ4UGe6l+v2EPrAwAAAABgKzbv6f559zl9uPigetcprCVvVVNYoLvaT92sK3EJadb/49hVvVA6j757/RktfLOqAj1d9OrUzboQfTubIwcAAAAA4NFsnnR/vf642lQMVqvywSrs766PmobLxdFe87adTrP+Z23K6NXKISqRx1OFcrtpVItSMgxpQ9SVbI4cAAAAAIBHs+nw8sSkZO07G603axU0l9nZmVS1kK92nLyRrjZu3bmrO3eT5ZXTIc3tCQkJSkj4q9c8Njb2sWIGAAAAACC9bNrTff1mou4mG/J1c7Io93Nz0uWHDC9/0MilB+Xv4ayqhXzT3B4ZGSlPT0/zIyws7LHjBgAAAAAgPWw+vPxxTFobpZ93n9eUV8vJ2cE+zToDBw5UdHS0+XHgwIFsjhIAAAAA8LSy6fBy75yOsrczpZo07XJcgvwe6P1+0Jfrjmry2qOa3bWSigd6PLSek5OTnJz+aismJubxggYAAAAAIJ1s2tPtmMNOJfN6auN9k6AlJxvaGHVVZfN7PXS/L347qgmrojSzc0WVCnp4PQAAAAAAbMnm63R3rRaqt+fvVniQlyKCPTV1/QndTExSy3LBkqR+c3fJ39NZ79UvJkmavPaoxq48rM/aRCjI20WXYu8tFebqmEOuTjY/HQAAAAAAzGyepTYpnUfX4hM1duVhXY5NUPE8HprZuaL83O8NCT9745ZMJpO5/qw/TirxbrK6z95h0U7v2oXVt26RbI0dAAAAAIBHsXnSLUkdqoSoQ5WQNLfN7VbZ4vmGAc9lQ0QAAAAAADy+f/Ts5QAAAAAAPMlIugEAAAAAsBKSbgAAAAAArISkGwAAAAAAKyHpBgAAAADASki6AQAAAACwEpJuAAAAAACshKQbAAAAAAArIekGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACvJYesAAFs5WKy4rUN4ahT/86CtQwAAAABsgp5uAAAAAACshKQbAAAAAAArIekGAAAAAMBKSLoBAAAAALASkm4AAAAAAKyEpBsAAAAAACsh6QYAAAAAwEpIugEAAAAAsBKSbgAAAACAzUVGRqpChQpyd3dX7ty51bRpUx06dMiizu3bt9WjRw/lypVLbm5uatGihS5evGijiNOHpBsAAAAAYHO//fabevTooT/++EMrV67UnTt39Pzzzys+Pt5cp2/fvvr55581f/58/fbbbzp37pyaN29uw6j/Xg5bBwAAAAAAwLJlyyyez5gxQ7lz59b27dtVo0YNRUdHa+rUqZozZ46ee+45SdL06dNVvHhx/fHHH3rmmWdsEfbfoqcbAAAAAPDEiY6OliT5+PhIkrZv3647d+6oTp065jrFihVTvnz5tGnTJpvEmB70dAMAAAAArCY2NlYxMTHm505OTnJycnrkPsnJyerTp4+qVq2qkiVLSpIuXLggR0dHeXl5WdT19/fXhQsXsjzurELSjadWq4G8/bPLXlsHAAAAAJsJCwuzeD506FANGzbskfv06NFD+/bt0/r1660YWfYg6wAAAAAAWM2BAweUN29e8/O/6+Xu2bOnFi9erHXr1ikoKMhcHhAQoMTERN24ccOit/vixYsKCAjI8rizCvd0AwAAAACsxt3dXR4eHubHw5JuwzDUs2dP/fjjj1q9erVCQ0MttpcrV04ODg5atWqVuezQoUM6deqUKleubNVzeBz0dAMAAAAAbK5Hjx6aM2eO/ve//8nd3d18n7anp6dcXFzk6empLl26qF+/fvLx8ZGHh4feeustVa5c+YmduVwi6QYAAAAAPAEmT54sSapVq5ZF+fTp09WxY0dJ0tixY2VnZ6cWLVooISFB9erV06RJk7I50owh6QYAAAAA2JxhGH9bx9nZWRMnTtTEiROzIaKswT3dAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFgJSTcAAAAAAFZC0g0AAAAAgJWQdAMAAAAAYCUk3QAAAAAAWAlJNwAAAAAAVkLSDQAAAACAlZB0AwAAAABgJSTdAAAAAABYCUk3AAAAAABWQtINAAAAAICVkHQDAAAAAGAlJN0AAAAAAFhJDlsH8M2mE5ry2zFdjktQ8UAPDX+hhCKCvdKse/hirMasOKy9Z6N19sYtDW4cpi7VQrM3YAAAAAAA0smmPd0/7z6nDxcfVO86hbXkrWoKC3RX+6mbdSUuIc36txLvKl+unHqvQTH5uTtlc7QAAAAAAGSMTZPur9cfV5uKwWpVPliF/d31UdNwuTjaa96202nWLx3spf80LK4XSueRoz0j4wEAAAAATzabZa6JScnadzZaVQv5/hWMnUlVC/lqx8kbtgoLAAAAAIAsY7N7uq/fTNTdZEO+bpbDxP3cnHT0cnyWHSchIUEJCX8NV4+Njc2ytgEAAAAAeJR//RjtyMhIeXp6mh9hYWG2DgkAAAAA8JSwWdLtndNR9namVJOmXY5LkJ9b1k2SNnDgQEVHR5sfBw4cyLK2AQAAAAB4FJsl3Y457FQyr6c2Rl0xlyUnG9oYdVVl83tl2XGcnJzk4eFhfri7u2dZ2wAAAAAAPIpN1+nuWi1Ub8/frfAgL0UEe2rq+hO6mZikluWC/6+9e4+qusr/P/46IBzupIBAjHJ0BMO8Qt5CRZPUzJbY5KSrEa8z5SxNl8o4hmk2ZU4OXmZGq9FCv67VaDmZ5qWfDoYZmRIG3hDNwoxQ0FBBE/Tw+f3h8kxH8M7Ho/Z8/MVn7332fh/WcsuLzz4fJEkTVuQqNNBLk/s8IOniw9cOllz8TPZ5e7WOnT6nvT+ckq9nPdmCfV32PgAAAAAAqI1LQ/cTbe7Xj2eqNHfTAZWWVyrm/gAtHdHB8Te4i07+JIvF4hh/7PQ5Pf73zxzX//r0G/3r02/UsUkDrXi2822vHwAAAACAq3Fp6JakoQ/bNPRhW619lwfpRg18VDjr8dtQFQAAAAAAt+6ef3o5AAAAAACuQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMckeE7v/bVqj4WZsVPXWD+i/IUu6Rk1cdv25XsR5Jy1T01A3qPfdTfbK/5PYUCgAAAAAw1YIFC2Sz2eTl5aWOHTtqx44dri7plrg8dH+U94NeWZuvcYlRWje2i1qE+yv57e06XlFZ6/icwz/q+eVf6emHGmn9813U68FQ/WHZlyo4Wn6bKwcAAAAA1KUVK1ZowoQJmj59unbu3Kk2bdqod+/eKim5e2+0ujx0L/7sWw3q0Ei/faiRokL99WpSK3l7uuu9L4/UOv6drEIlRIfo2YRfq1lDf03s1VwP3h+opdsKb2/hAAAAAIA6NWfOHP3+97/X8OHD1aJFC7355pvy8fHRO++84+rSbppLQ3fVhWrtKTql+GbBjjY3N4vimwVr5+GTtb7mq8NlTuMlqVt0iHYeLjOzVAAAAACAiaqqqpSTk6PExERHm5ubmxITE7Vt2zYXVnZr6rly8bKzVbJXGwr2szq1h/hZdaj0TK2vKa2oVLCf52XjPa94HL2yslKVlf/rO3XqlCSpuLj4Vko31YXTx11dwi+C/Se7q0v4xfj+++9dXQJMxJ51+7Bv3R7sWfc+9q3bh33r9rhT961LmevUqVMKCAhwtFutVlmt1hrjjx8/LrvdrtDQUKf20NBQ7d+/39xiTeTS0H07vPbaa5oxY0aN9g4dOrigGtxJilxdwC9Io9GNXF0CcE9g37o92LOAusO+dXvc6ftWy5Ytna6nT5+ul156yTXFuIBLQ3d9H0+5u1lq3KUurahUiF/N33xIF++CH6+oumx8VY275ZdMmTJFEyZMcFxfuHBB+fn5atSokdzcXP6RduC6lZeXq0WLFtq3b5/8/f1dXQ4AXBP7FoC7DftW3aqurtZ3332nFi1aqF69/0XP2u5yS1JwcLDc3d117Ngxp/Zjx44pLCzM1FrN5NLQ7VnPTS0jAvX518fV+8GL38TqakOff31CyQ9H1vqadpH19fnXxzWySxNH22cHSxUbWb/W8bUdXYiPj6+jdwDcPqdPn5YkRUREOB3PAYA7FfsWgLsN+1bda9y48XWP9fT0VFxcnDIyMpSUlCTpYnDPyMjQmDFjTKrQfC6/1TuqSxP9O/uIVuZ8r69LypX64R6drbqggXEXj0hMWJGrv378v/P7I+Jt2nKgVIs+/UZfl1Ro7qYD2l10SkM721z0DgAAAAAAdWHChAlatGiRli5dqvz8fI0ePVpnzpzR8OHDXV3aTXP5Z7qfaHO/fjxTpbmbDqi0vFIx9wdo6YgOCvG/eHe66ORPslgsjvFxkQ00f1A7pW0s0Oz/VyBbsI/+NeQhNQ/j+AcAAAAA3M2efvpplZaWatq0aTp69Kjatm2rjz/+uMbD1e4mFsMwDFcXAeDaKisr9dprr2nKlClX/BwMANxJ2LcA3G3Yt2AGQjcAAAAAACZx+We6AQAAAAC4VxG6AQAAAAAwCaEbuAGFhYWyWCzKzc29pXm6d++u8ePHO65tNpvmzZt3S3PeDFetC+DecvmeBgCuNmzYMMefnDLTkiVLdN9995m+Du5uLn96OQDXyc7Olq+vr6vLAIDrZrFYtGrVqtvywzSAu9f8+fPFo6twpyB0A79gISEhri4BAGS322WxWOTmxgE8AHUjMDDQ1SUADvzvBtSiurpar7/+upo1ayar1arGjRvr1VdfdfR/88036tGjh3x8fNSmTRtt27bN0XfixAkNHjxYERER8vHxUatWrfTvf//7htY/efKkRo0apZCQEAUEBOiRRx5RXl6eo/+ll15S27ZttWzZMtlsNgUGBmrQoEEqLy93jCkvL9czzzwjX19fhYeHa+7cudc81m6xWLR48WINGDBAPj4+ioqK0po1a5xqW7NmjaKiouTl5aUePXpo6dKlslgsOnny5A29RwDm6969u8aOHavx48erfv36Cg0N1aJFi3TmzBkNHz5c/v7+atasmTZs2OB4zZYtW9ShQwdZrVaFh4frz3/+sy5cuODoP3PmjJKTk+Xn56fw8HClpaXVWLeyslKTJk1SRESEfH191bFjR2VmZjr6Lx3HXLNmjVq0aCGr1arvvvtO2dnZevTRRxUcHKzAwEAlJCRo586djtfZbDZJ0oABA2SxWBzXkrR69WrFxsbKy8tLTZs21YwZM5zqBnBvWrlypVq1aiVvb28FBQUpMTFRZ86cqXG8/Gb2w8zMTFksFq1bt06tW7eWl5eXOnXqpD179ly1JvYjXI7QDdRiypQpmjVrll588UXt27dP7777rkJDQx39qampmjRpknJzcxUdHa3Bgwc7NtNz584pLi5O69at0549e/SHP/xBQ4YM0Y4dO657/YEDB6qkpEQbNmxQTk6OYmNj1bNnT/3444+OMYcOHdKHH36otWvXau3atdqyZYtmzZrl6J8wYYKysrK0Zs0abdq0SVu3bnX64fVKZsyYod/+9rfatWuX+vbtq2eeecax7rfffqunnnpKSUlJysvL07PPPqvU1NTrfl8Abr+lS5cqODhYO3bs0NixYzV69GgNHDhQDz/8sHbu3KlevXppyJAhOnv2rIqKitS3b1+1b99eeXl5euONN/T222/rlVdeccyXkpKiLVu2aPXq1dq4caMyMzNr7C1jxozRtm3btHz5cu3atUsDBw5Unz59dPDgQceYs2fP6q9//asWL16svXv3qmHDhiovL9fQoUP12Wef6YsvvlBUVJT69u3r+IVidna2JCk9PV3FxcWO661btyo5OVnjxo3Tvn379NZbb2nJkiVOvywFcO8pLi7W4MGDNWLECOXn5yszM1NPPvnkFY+V38h++HMpKSlKS0tTdna2QkJC9MQTT+j8+fO1rsF+hFoZAJycPn3asFqtxqJFi2r0ffvtt4YkY/HixY62vXv3GpKM/Pz8K875+OOPGxMnTnRcJyQkGOPGjXNcR0ZGGnPnzjUMwzC2bt1qBAQEGOfOnXOa49e//rXx1ltvGYZhGNOnTzd8fHyM06dPO/pTUlKMjh07Ot6Dh4eH8f777zv6T548afj4+FxxXcMwDEnG1KlTHdcVFRWGJGPDhg2GYRjG5MmTjZYtWzrVlZqaakgyysrKrvj+AbhGQkKC0aVLF8f1hQsXDF9fX2PIkCGOtuLiYkOSsW3bNuOFF14wmjdvblRXVzv6FyxYYPj5+Rl2u90oLy83PD09jffee8/Rf+LECcPb29uxtxw+fNhwd3c3ioqKnGrp2bOnMWXKFMMwDCM9Pd2QZOTm5l61frvdbvj7+xsfffSRo02SsWrVqhpzz5w506lt2bJlRnh4+FXnB3B3y8nJMSQZhYWFNfqGDh1q9O/f33F9o/uhYRjGJ598Ykgyli9f7hhzac9bsWKFYRgX97PAwEBHP/sRasNnuoHL5Ofnq7KyUj179rzimNatWzu+Dg8PlySVlJTogQcekN1u18yZM/Xee++pqKhIVVVVqqyslI+Pz3Wtn5eXp4qKCgUFBTm1//TTTzp06JDj2mazyd/f36mOkpISSRePv58/f14dOnRw9AcGBqp58+bXXP/n783X11cBAQGOeQsKCtS+fXun8T9fA8Cd5+f/pt3d3RUUFKRWrVo52i6d4ikpKVF+fr46d+4si8Xi6I+Pj1dFRYW+//57lZWVqaqqSh07dnT0N2jQwGlv2b17t+x2u6Kjo53qqKysdNrXPD09nWqTpGPHjmnq1KnKzMxUSUmJ7Ha7zp49q+++++6q7zEvL09ZWVlOd5LsdrvOnTuns2fPXvf+C+Du0qZNG/Xs2VOtWrVS79691atXLz311FOqX79+reNvZD/8uc6dOzu+vrTn5efn17oG+xFqQ+gGLuPt7X3NMR4eHo6vL/1wWl1dLUmaPXu25s+fr3nz5qlVq1by9fXV+PHjVVVVdV3rV1RUKDw83Onzj5f8/E9S/LyGS3VcquFWmDUvANeo7d/01fawW1VRUSF3d3fl5OTI3d3dqc/Pz8/xtbe3t1O4l6ShQ4fqxIkTmj9/viIjI2W1WtW5c+dr7p8VFRWaMWOGnnzyyRp9Xl5et/BuANzJ3N3dtWnTJn3++efauHGj/vGPfyg1NVXbt2+vdfzt2A/Zj1AbQjdwmaioKHl7eysjI0OjRo264ddnZWWpf//++t3vfifp4sZ94MABtWjR4rpeHxsbq6NHj6pevXpODwm6EU2bNpWHh4eys7PVuHFjSdKpU6d04MABdevW7abmlKTmzZtr/fr1Tm2XPlMJ4O4XExOj//znPzIMw/HDZ1ZWlvz9/fWrX/1KDRo0kIeHh7Zv3+7YW8rKynTgwAElJCRIktq1aye73a6SkhJ17dr1htbPysrSwoUL1bdvX0nSkSNHdPz4cacxHh4estvtTm2xsbEqKChQs2bNbup9A7h7WSwWxcfHKz4+XtOmTVNkZKRWrVpVp2t88cUXNfa8mJiYWseyH6E2hG7gMl5eXpo8ebL+9Kc/ydPTU/Hx8SotLdXevXuveuT8kqioKK1cuVKff/656tevrzlz5ujYsWPXHboTExPVuXNnJSUl6fXXX1d0dLR++OEHrVu3TgMGDNBDDz10zTn8/f01dOhQpaSkqEGDBmrYsKGmT58uNze3GneWbsSzzz6rOXPmaPLkyRo5cqRyc3O1ZMkSSbqleQHcGf74xz9q3rx5Gjt2rMaMGaOCggJNnz5dEyZMkJubm/z8/DRy5EilpKQoKChIDRs2VGpqqtOf+oqOjtYzzzyj5ORkpaWlqV27diotLVVGRoZat26txx9//IrrR0VFadmyZXrooYd0+vRppaSk1Dh9ZLPZlJGRofj4eFmtVtWvX1/Tpk1Tv3791LhxYz311FNyc3NTXl6e9uzZ4/QQOAD3lu3btysjI0O9evVSw4YNtX37dpWWliomJka7du2qs3VefvllBQUFKTQ0VKmpqQoODnZ6MvrPsR+hNjy9HKjFiy++qIkTJ2ratGmKiYnR008/XePzPVcydepUxcbGqnfv3urevbvCwsKuuDHXxmKxaP369erWrZuGDx+u6OhoDRo0SIcPH3Z6gvq1zJkzR507d1a/fv2UmJio+Ph4xcTE3NLRpiZNmmjlypX64IMP1Lp1a73xxhuOp5dbrdabnhfAnSEiIkLr16/Xjh071KZNGz333HMaOXKkpk6d6hgze/Zsde3aVU888YQSExPVpUsXxcXFOc2Tnp6u5ORkTZw4Uc2bN1dSUpLTyZsrefvtt1VWVqbY2FgNGTJEzz//vBo2bOg0Ji0tTZs2bVKjRo3Url07SVLv3r21du1abdy4Ue3bt1enTp00d+5cRUZG1tF3BsCdKCAgQJ9++qn69u2r6OhoTZ06VWlpaXrsscfqdJ1Zs2Zp3LhxiouL09GjR/XRRx/J09Oz1rHsR6iNxTCu8Ex9APeUM2fOKCIiQmlpaRo5cmSdzfvqq6/qzTff1JEjR+psTgAAAFfLzMxUjx49VFZW5vRcHeBGcbwcuEd99dVX2r9/vzp06KBTp07p5ZdfliT179//luZduHCh2rdvr6CgIGVlZWn27NkaM2ZMXZQMAAAA3HMI3cA97G9/+5sKCgrk6empuLg4bd26VcHBwbc058GDB/XKK6/oxx9/VOPGjTVx4kRNmTKljioGAAAA7i0cLwcAAAAAwCQ8SA0AAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBADCJxWLRhx9+6Ljev3+/OnXqJC8vL7Vt27bWtsLCQlksFuXm5tZZHTabTfPmzauz+QAAwPUjdAMAcIOGDRsmi8Uii8UiDw8PhYaG6tFHH9U777yj6upqx7ji4mI99thjjuvp06fL19dXBQUFysjIqLWtUaNGKi4uVsuWLU2r//JfBgAAAPMQugEAuAl9+vRRcXGxCgsLtWHDBvXo0UPjxo1Tv379dOHCBUlSWFiYrFar4zWHDh1Sly5dFBkZqaCgoFrb3N3dFRYWpnr16rnkfQEAgLpF6AYA4CZYrVaFhYUpIiJCsbGxeuGFF7R69Wpt2LBBS5YskeR8R9lisSgnJ0cvv/yyLBaLXnrppVrbajtevnfvXvXr108BAQHy9/dX165ddejQIUlS9+7dNX78eKfakpKSNGzYsFrrttlskqQBAwbIYrHIZrOpsLBQbm5u+vLLL53Gzps3T5GRkU537wEAwI0hdAMAUEceeeQRtWnTRh988EGNvuLiYj344IOaOHGiiouLNWnSpFrbLldUVKRu3brJarVq8+bNysnJ0YgRIxx3029Udna2JCk9PV3FxcXKzs6WzWZTYmKi0tPTncamp6dr2LBhcnPjxwUAAG4WZ9cAAKhDDzzwgHbt2lWj/dKRcT8/P4WFhUmS/Pz8arQdP37c6XULFixQYGCgli9fLg8PD0lSdHT0TdcXEhIiSbrvvvsca0rSqFGj9Nxzz2nOnDmyWq3auXOndu/erdWrV9/0WgAAgDvdAADUKcMwZLFY6my+3Nxcde3a1RG4zZKUlCR3d3etWrVKkrRkyRL16NHDcRwdAADcHEI3AAB1KD8/X02aNKmz+by9va/a7+bmJsMwnNrOnz9/w+t4enoqOTlZ6enpqqqq0rvvvqsRI0bc8DwAAMAZoRsAgDqyefNm7d69W7/5zW/qbM7WrVtr69atVwzSISEhKi4udlzb7Xbt2bPnqnN6eHjIbrfXaB81apT++9//auHChbpw4YKefPLJWyseAAAQugEAuBmVlZU6evSoioqKtHPnTs2cOVP9+/dXv379lJycXGfrjBkzRqdPn9agQYP05Zdf6uDBg1q2bJkKCgokXXx427p167Ru3Trt379fo0eP1smTJ686p81mU0ZGho4ePaqysjJHe0xMjDp16qTJkydr8ODB17zLDgAAro3QDQDATfj4448VHh4um82mPn366JNPPtHf//53rV69Wu7u7nW2TlBQkDZv3qyKigolJCQoLi5OixYtcnzGe8SIERo6dKiSk5OVkJCgpk2bqkePHledMy0tTZs2bVKjRo3Url07p76RI0eqqqqKo+UAANQRi3H5B8EAAMAv1l/+8he9//77tT6BHQAA3DjudAMAAFVUVGjPnj365z//qbFjx7q6HAAA7hmEbgAAoDFjxiguLk7du3fnaDkAAHWI4+UAAAAAAJiEO90AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmOT/A5yEpUFvWzg1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "if \"bird\" in dataset_name:\n",
    "    # Ensure all indices align with sorted difficulties\n",
    "    difficulty_order = sorted(df[\"difficulty\"].unique())\n",
    "\n",
    "    # Calculate metrics, ensuring alignment\n",
    "    accuracy_per_difficulty = (\n",
    "        df.groupby(\"difficulty\")[\"is_correct\"]\n",
    "        .mean()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "    successful_examples = (\n",
    "        df[df[\"successful_run\"] == True][\"difficulty\"]\n",
    "        .value_counts()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "    unsuccessful_examples = (\n",
    "        df[df[\"successful_run\"] == False][\"difficulty\"]\n",
    "        .value_counts()\n",
    "        .reindex(difficulty_order, fill_value=0)\n",
    "    )\n",
    "\n",
    "    # Calculate total examples for consistency (or use successful + unsuccessful)\n",
    "    examples_per_difficulty = successful_examples + unsuccessful_examples\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))  # Adjust figure size if needed\n",
    "\n",
    "    # Plot accuracy per difficulty\n",
    "    color = \"tab:blue\"\n",
    "    ax1.set_xlabel(\"Difficulty\")\n",
    "    ax1.set_ylabel(\"Accuracy\", color=color)\n",
    "    ax1.bar(\n",
    "        difficulty_order,\n",
    "        accuracy_per_difficulty,\n",
    "        color=color,\n",
    "        label=\"Accuracy\",\n",
    "        width=0.3,\n",
    "        align=\"center\",\n",
    "    )\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=color)\n",
    "\n",
    "    # Create a secondary y-axis to plot examples\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel(\"Number of Examples\")\n",
    "\n",
    "    # Plot examples and unsuccessful runs per difficulty\n",
    "    width = 0.3  # Adjust bar width\n",
    "    positions = range(len(difficulty_order))  # Shared x-axis positions\n",
    "\n",
    "    # Stacked bar: successful and unsuccessful runs\n",
    "    ax2.bar(\n",
    "        [p + width for p in positions],\n",
    "        successful_examples,\n",
    "        color=\"tab:green\",\n",
    "        label=\"Successful Examples\",\n",
    "        width=width,\n",
    "        align=\"center\",\n",
    "    )\n",
    "    ax2.bar(\n",
    "        [p + width for p in positions],\n",
    "        unsuccessful_examples,\n",
    "        bottom=successful_examples,\n",
    "        color=\"tab:red\",\n",
    "        label=\"Unsuccessful Examples\",\n",
    "        width=width,\n",
    "        align=\"center\",\n",
    "    )\n",
    "\n",
    "    # Customize tick positions and labels\n",
    "    ax1.set_xticks([p + width for p in positions])\n",
    "    ax1.set_xticklabels(difficulty_order)\n",
    "\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # Adjust legend placement\n",
    "    fig.legend(\n",
    "        loc=\"upper left\",\n",
    "        bbox_to_anchor=(0.2, 0.9),\n",
    "        bbox_transform=ax1.transAxes,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Accuracy, Number of Examples, and Unsuccessful Runs per Difficulty\")\n",
    "\n",
    "    # Save the figure\n",
    "    fig.savefig(f\"runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.png\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.99%\n",
      "Proportion of successful runs: 0.97\n",
      "Combined Metric: 0.90\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[94, 28], [5, 67]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset_name = \"bird-noisy\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "model_type = \"two_shot\"\n",
    "\n",
    "df = pd.read_csv(f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}.csv\")\n",
    "\n",
    "successful_runs_df = df[df['successful_run']]\n",
    "\n",
    "# Calculate the accuracy using is_correct\n",
    "accuracy = successful_runs_df['is_correct'].mean() * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Calculate the proportion of successful runs\n",
    "successful_runs_ratio = df['successful_run'].mean()\n",
    "print(f\"Proportion of successful runs: {successful_runs_ratio:.2f}\")\n",
    "\n",
    "# Normalize both metrics to be between 0 and 1\n",
    "# Accuracy is between 0 and 100, so normalize it by dividing by 100\n",
    "normalized_accuracy = accuracy / 100\n",
    "\n",
    "# Successful runs are already a proportion, so no need to normalize\n",
    "# But if successful_run is binary (True/False), you can normalize it by taking the mean\n",
    "normalized_successful_runs = successful_runs_ratio\n",
    "\n",
    "# Calculate the combined metric (arithmetic mean of both metrics)\n",
    "combined_metric = (normalized_accuracy + normalized_successful_runs) / 2\n",
    "print(f\"Combined Metric: {combined_metric:.2f}\")\n",
    "\n",
    "# Now, let's compute the confusion matrix:\n",
    "# True Positives (TP) -> is_correct == True and noised == False\n",
    "# False Positives (FP) -> is_correct == False and noised == True\n",
    "# True Negatives (TN) -> is_correct == False and noised == False\n",
    "# False Negatives (FN) -> is_correct == True and noised == True\n",
    "\n",
    "# Extracting the confusion matrix elements based on the conditions\n",
    "TP = len(successful_runs_df[(successful_runs_df['is_correct'] == True) & (successful_runs_df['noised'] == False)])\n",
    "FP = len(successful_runs_df[(successful_runs_df['is_correct'] == False) & (successful_runs_df['noised'] == False)])\n",
    "TN = len(successful_runs_df[(successful_runs_df['is_correct'] == True) & (successful_runs_df['noised'] == True)])\n",
    "FN = len(successful_runs_df[(successful_runs_df['is_correct'] == False) & (successful_runs_df['noised'] == True)])\n",
    "\n",
    "# Construct the confusion matrix\n",
    "cm = [[TN, FP], [FN, TP]]\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted False', 'Predicted True'], yticklabels=['Actual False', 'Actual True'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig(f\"./runs/feedback_agent/{dataset_name}/{model_name}/{model_type}_confusion_matrix.png\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Support</th>\n",
       "      <th>ASR Score</th>\n",
       "      <th>Accuracy_Performance_Gain</th>\n",
       "      <th>ASR Score Improvement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th>two_shot</th>\n",
       "      <th>two_shot</th>\n",
       "      <th>two_shot</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claude-3-5-sonnet-20240620</th>\n",
       "      <td>0.835821</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.735522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-35-turbo</th>\n",
       "      <td>0.715000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.707420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>0.785000</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.871728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>0.810000</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.882809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Support ASR Score  \\\n",
       "Prompt                      two_shot two_shot  two_shot   \n",
       "Model                                                     \n",
       "claude-3-5-sonnet-20240620  0.835821     44.0  0.735522   \n",
       "gpt-35-turbo                0.715000    140.0  0.707420   \n",
       "gpt-4o                      0.785000    196.0  0.871728   \n",
       "gpt-4o-mini                 0.810000    194.0  0.882809   \n",
       "\n",
       "                           Accuracy_Performance_Gain ASR Score Improvement  \n",
       "Prompt                                                                      \n",
       "Model                                                                       \n",
       "claude-3-5-sonnet-20240620                       0.0                   0.0  \n",
       "gpt-35-turbo                                     0.0                   0.0  \n",
       "gpt-4o                                           0.0                   0.0  \n",
       "gpt-4o-mini                                      0.0                   0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = f\"./runs/feedback_agent/{dataset_name}\"\n",
    "\n",
    "# Initialize an empty dictionary to store the data\n",
    "data = {}\n",
    "\n",
    "# Iterate through each model directory\n",
    "for model in os.listdir(base_dir):\n",
    "    model_dir = os.path.join(base_dir, model)\n",
    "    if os.path.isdir(model_dir):\n",
    "        data[model] = {}\n",
    "        # Iterate through each CSV file in the model directory\n",
    "        for csv_file in os.listdir(model_dir):\n",
    "            if csv_file.endswith(\".csv\"):\n",
    "                csv_path = os.path.join(model_dir, csv_file)\n",
    "                prompt = os.path.splitext(csv_file)[0]\n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(csv_path)\n",
    "                data[model][prompt] = df\n",
    "\n",
    "# Concatenate the DataFrames along a new axis\n",
    "concat_data = {(model, prompt): df for model, prompts in data.items() for prompt, df in prompts.items()}\n",
    "\n",
    "# Calculate accuracy, support, and one-shot accuracy for each model/prompt combination\n",
    "accuracies = {key: df[\"is_correct\"].mean() for key, df in concat_data.items()}\n",
    "supports = {key: df[\"successful_run\"].sum() for key, df in concat_data.items()}\n",
    "one_shot_accuracies = {key: (df[\"is_correct\"] == True).sum() / len(df) if len(df) > 0 else 0 for key, df in concat_data.items()}\n",
    "\n",
    "def calculate_combined_metric(df):\n",
    "    accuracy = df[\"is_correct\"].mean()\n",
    "    successful_run_ratio = df[\"successful_run\"].mean()\n",
    "    \n",
    "    # Harmonic mean of accuracy and successful_run_ratio\n",
    "    if accuracy + successful_run_ratio == 0:  # Prevent division by zero\n",
    "        combined_metric = 0\n",
    "    else:\n",
    "        combined_metric = 2 * (accuracy * successful_run_ratio) / (accuracy + successful_run_ratio)\n",
    "    \n",
    "    return combined_metric\n",
    "\n",
    "\n",
    "combined_metrics = {key: calculate_combined_metric(df) for key, df in concat_data.items()}\n",
    "\n",
    "# Convert the accuracies, supports, one-shot accuracies, and combined metrics dictionaries to DataFrames for better visualization\n",
    "accuracy_df = pd.DataFrame(\n",
    "    list(accuracies.items()), columns=[\"Model_Prompt\", \"Accuracy\"]\n",
    ")\n",
    "support_df = pd.DataFrame(list(supports.items()), columns=[\"Model_Prompt\", \"Support\"])\n",
    "combined_metric_df = pd.DataFrame(\n",
    "    list(combined_metrics.items()), columns=[\"Model_Prompt\", \"ASR Score\"]\n",
    ")\n",
    "\n",
    "# Merge the accuracy, support, one-shot accuracy, and combined metric DataFrames\n",
    "merged_df = pd.merge(accuracy_df, support_df, on=\"Model_Prompt\")\n",
    "merged_df = pd.merge(merged_df, combined_metric_df, on=\"Model_Prompt\")\n",
    "\n",
    "# Split the Model_Prompt column into separate Model and Prompt columns\n",
    "merged_df[[\"Model\", \"Prompt\"]] = pd.DataFrame(\n",
    "    merged_df[\"Model_Prompt\"].tolist(), index=merged_df.index\n",
    ")\n",
    "merged_df.drop(columns=[\"Model_Prompt\"], inplace=True)\n",
    "\n",
    "# Pivot the DataFrame to have models as rows, prompts as columns, and accuracy, support, one-shot accuracy, and combined metric as values\n",
    "pivot_df = merged_df.pivot(\n",
    "    index=\"Model\", columns=\"Prompt\", values=[\"Accuracy\", \"Support\", \"ASR Score\"]\n",
    ")\n",
    "\n",
    "accuracy_performance_gain = pivot_df[\"Accuracy\"].max(axis=1) - pivot_df[\"Accuracy\"].min(axis=1)\n",
    "pivot_df[\"Accuracy_Performance_Gain\"] = accuracy_performance_gain\n",
    "\n",
    "\n",
    "# Calculate the performance gain from worst to best for the Combined Metric\n",
    "combined_metric_performance_gain = pivot_df[\"ASR Score\"].max(axis=1) - pivot_df[\"ASR Score\"].min(axis=1)\n",
    "pivot_df[\"ASR Score Improvement\"] = combined_metric_performance_gain\n",
    "\n",
    "pivot_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmsagents-texttosql-bQPeKkIa-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
